{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch-Pruning(DepGraph)\n",
    "1. pruner.function: https://github.com/VainF/Torch-Pruning/blob/master/torch_pruning/pruner/function.py\n",
    "2. torch_pruning.dependency: https://github.com/VainF/Torch-Pruning/blob/master/torch_pruning/dependency.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] 找不到指定的程序。 Error loading \"c:\\Users\\user\\anaconda3\\envs\\YOLOv8_env\\lib\\site-packages\\torch\\lib\\c10_cuda.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_pruning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchsummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\YOLOv8_env\\lib\\site-packages\\torch\\__init__.py:132\u001b[0m\n\u001b[0;32m    130\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    131\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] 找不到指定的程序。 Error loading \"c:\\Users\\user\\anaconda3\\envs\\YOLOv8_env\\lib\\site-packages\\torch\\lib\\c10_cuda.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_pruning as tp\n",
    "from torchsummary import summary\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadro RTX 3000 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    device = \"cuda\"\n",
    "    print(torch.cuda.get_device_name())\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"Use CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pytorch weights\n",
    "PATH = r'my_weights/Resnet18_e20_b5_t70_v30.pth'\n",
    "model = torch.load(PATH).to(device)\n",
    "print(summary(model, input_size=(3, 32, 32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Minimal Example of DepGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Build dependency graph for a resnet18. This requires a dummy input for forwarding\n",
    "DG = tp.DependencyGraph().build_dependency(model, example_inputs=torch.randn(1,3,32,32).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on conv1 (Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)) => prune_out_channels on conv1 (Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)), idxs (3) =[2, 6, 9]  (Pruning Root)\n",
      "[1] prune_out_channels on conv1 (Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)) => prune_out_channels on bn1 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), idxs (3) =[2, 6, 9] \n",
      "[2] prune_out_channels on bn1 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_20(ReluBackward0), idxs (3) =[2, 6, 9] \n",
      "[3] prune_out_channels on _ElementWiseOp_20(ReluBackward0) => prune_out_channels on _ElementWiseOp_19(MaxPool2DWithIndicesBackward0), idxs (3) =[2, 6, 9] \n",
      "[4] prune_out_channels on _ElementWiseOp_19(MaxPool2DWithIndicesBackward0) => prune_out_channels on _ElementWiseOp_18(AddBackward0), idxs (3) =[2, 6, 9] \n",
      "[5] prune_out_channels on _ElementWiseOp_19(MaxPool2DWithIndicesBackward0) => prune_in_channels on layer1.0.conv1 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), idxs (3) =[2, 6, 9] \n",
      "[6] prune_out_channels on _ElementWiseOp_18(AddBackward0) => prune_out_channels on layer1.0.bn2 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), idxs (3) =[2, 6, 9] \n",
      "[7] prune_out_channels on _ElementWiseOp_18(AddBackward0) => prune_out_channels on _ElementWiseOp_17(ReluBackward0), idxs (3) =[2, 6, 9] \n",
      "[8] prune_out_channels on _ElementWiseOp_17(ReluBackward0) => prune_out_channels on _ElementWiseOp_16(AddBackward0), idxs (3) =[2, 6, 9] \n",
      "[9] prune_out_channels on _ElementWiseOp_17(ReluBackward0) => prune_in_channels on layer1.1.conv1 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), idxs (3) =[2, 6, 9] \n",
      "[10] prune_out_channels on _ElementWiseOp_16(AddBackward0) => prune_out_channels on layer1.1.bn2 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), idxs (3) =[2, 6, 9] \n",
      "[11] prune_out_channels on _ElementWiseOp_16(AddBackward0) => prune_out_channels on _ElementWiseOp_15(ReluBackward0), idxs (3) =[2, 6, 9] \n",
      "[12] prune_out_channels on _ElementWiseOp_15(ReluBackward0) => prune_in_channels on layer2.0.downsample.0 (Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)), idxs (3) =[2, 6, 9] \n",
      "[13] prune_out_channels on _ElementWiseOp_15(ReluBackward0) => prune_in_channels on layer2.0.conv1 (Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)), idxs (3) =[2, 6, 9] \n",
      "[14] prune_out_channels on layer1.1.bn2 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer1.1.conv2 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), idxs (3) =[2, 6, 9] \n",
      "[15] prune_out_channels on layer1.0.bn2 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer1.0.conv2 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), idxs (3) =[2, 6, 9] \n",
      "--------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. To prune the output channels of model.conv1, we need to find the corresponding group with a pruning function and pruning indices.\n",
    "group = DG.get_pruning_group( model.conv1, tp.prune_conv_out_channels, idxs=[2, 6, 9] )\n",
    "print(group.details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 61, 16, 16]           8,967\n",
      "       BatchNorm2d-2           [-1, 61, 16, 16]             122\n",
      "              ReLU-3           [-1, 61, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 61, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]          35,136\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 61, 8, 8]          35,136\n",
      "       BatchNorm2d-9             [-1, 61, 8, 8]             122\n",
      "             ReLU-10             [-1, 61, 8, 8]               0\n",
      "       BasicBlock-11             [-1, 61, 8, 8]               0\n",
      "           Conv2d-12             [-1, 64, 8, 8]          35,136\n",
      "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
      "             ReLU-14             [-1, 64, 8, 8]               0\n",
      "           Conv2d-15             [-1, 61, 8, 8]          35,136\n",
      "      BatchNorm2d-16             [-1, 61, 8, 8]             122\n",
      "             ReLU-17             [-1, 61, 8, 8]               0\n",
      "       BasicBlock-18             [-1, 61, 8, 8]               0\n",
      "           Conv2d-19            [-1, 128, 4, 4]          70,272\n",
      "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
      "             ReLU-21            [-1, 128, 4, 4]               0\n",
      "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
      "           Conv2d-24            [-1, 128, 4, 4]           7,808\n",
      "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
      "             ReLU-26            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
      "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
      "             ReLU-30            [-1, 128, 4, 4]               0\n",
      "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
      "             ReLU-33            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
      "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
      "             ReLU-37            [-1, 256, 2, 2]               0\n",
      "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
      "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
      "             ReLU-42            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
      "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
      "             ReLU-46            [-1, 256, 2, 2]               0\n",
      "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
      "             ReLU-49            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
      "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-53            [-1, 512, 1, 1]               0\n",
      "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-58            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
      "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-62            [-1, 512, 1, 1]               0\n",
      "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-65            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,678,301\n",
      "Trainable params: 11,678,301\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.26\n",
      "Params size (MB): 44.55\n",
      "Estimated Total Size (MB): 45.82\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 3. Do the pruning\n",
    "if DG.check_pruning_group(group): # avoid over-pruning, i.e., channels=0.\n",
    "    print(DG.check_pruning_group(group))\n",
    "    group.prune()\n",
    "\n",
    "print(summary(model, input_size=(3, 32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Save & Load\n",
    "model.zero_grad() # clear gradients to avoid a large file size\n",
    "torch.save(model, PATH.replace(\".pth\", \"(DG).pth\")) # !! no .state_dict here since the structure has been changed after pruning\n",
    "# model = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupTaylorImportance + MetaPruner\n",
    "1. Importance : https://github.com/VainF/Torch-Pruning/blob/adf1b075aa4f53043937d29e1953516ef477fc81/torch_pruning/pruner/importance.py#L37\n",
    "2. Pruner : https://github.com/VainF/Torch-Pruning/tree/master/torch_pruning/pruner/algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13968\\3720322140.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(PATH).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
      "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
      "             ReLU-14             [-1, 64, 8, 8]               0\n",
      "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
      "             ReLU-17             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
      "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
      "             ReLU-21            [-1, 128, 4, 4]               0\n",
      "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
      "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
      "             ReLU-26            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
      "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
      "             ReLU-30            [-1, 128, 4, 4]               0\n",
      "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
      "             ReLU-33            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
      "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
      "             ReLU-37            [-1, 256, 2, 2]               0\n",
      "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
      "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
      "             ReLU-42            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
      "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
      "             ReLU-46            [-1, 256, 2, 2]               0\n",
      "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
      "             ReLU-49            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
      "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-53            [-1, 512, 1, 1]               0\n",
      "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-58            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
      "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-62            [-1, 512, 1, 1]               0\n",
      "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-65            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.29\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 45.90\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "PATH = r'my_weights/Resnet18_e20_b5_t70_v30.pth'\n",
    "model = torch.load(PATH).to(device)\n",
    "summary(model, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 1. Importance criterion\n",
    "imp = tp.importance.GroupTaylorImportance()\n",
    "\n",
    "# 2. Initialize a pruner with the model and the importance criterion\n",
    "ignored_layers = []\n",
    "for m in model.modules():\n",
    "    if isinstance(m, torch.nn.Linear) and m.out_features == 10:\n",
    "        ignored_layers.append(m) # DO NOT prune the final classifier!\n",
    "print(ignored_layers)\n",
    "\n",
    "example_inputs = torch.randn(1, 3, 32, 32).to(device)\n",
    "pruner = tp.pruner.MetaPruner( # We can always choose MetaPruner if sparse training is not required.\n",
    "    model,\n",
    "    example_inputs = example_inputs,\n",
    "    importance = imp,\n",
    "    pruning_ratio = 0.5,\n",
    "    ignored_layers = ignored_layers,\n",
    ")\n",
    "\n",
    "# 3. Prune & finetune the model\n",
    "base_macs, base_nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "if isinstance(imp, tp.importance.GroupTaylorImportance):\n",
    "    loss = model(example_inputs).sum() \n",
    "    loss.backward() # before pruner.step()\n",
    "\n",
    "pruner.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 16, 16]           4,704\n",
      "       BatchNorm2d-2           [-1, 32, 16, 16]              64\n",
      "              ReLU-3           [-1, 32, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 32, 8, 8]               0\n",
      "            Conv2d-5             [-1, 32, 8, 8]           9,216\n",
      "       BatchNorm2d-6             [-1, 32, 8, 8]              64\n",
      "              ReLU-7             [-1, 32, 8, 8]               0\n",
      "            Conv2d-8             [-1, 32, 8, 8]           9,216\n",
      "       BatchNorm2d-9             [-1, 32, 8, 8]              64\n",
      "             ReLU-10             [-1, 32, 8, 8]               0\n",
      "       BasicBlock-11             [-1, 32, 8, 8]               0\n",
      "           Conv2d-12             [-1, 32, 8, 8]           9,216\n",
      "      BatchNorm2d-13             [-1, 32, 8, 8]              64\n",
      "             ReLU-14             [-1, 32, 8, 8]               0\n",
      "           Conv2d-15             [-1, 32, 8, 8]           9,216\n",
      "      BatchNorm2d-16             [-1, 32, 8, 8]              64\n",
      "             ReLU-17             [-1, 32, 8, 8]               0\n",
      "       BasicBlock-18             [-1, 32, 8, 8]               0\n",
      "           Conv2d-19             [-1, 64, 4, 4]          18,432\n",
      "      BatchNorm2d-20             [-1, 64, 4, 4]             128\n",
      "             ReLU-21             [-1, 64, 4, 4]               0\n",
      "           Conv2d-22             [-1, 64, 4, 4]          36,864\n",
      "      BatchNorm2d-23             [-1, 64, 4, 4]             128\n",
      "           Conv2d-24             [-1, 64, 4, 4]           2,048\n",
      "      BatchNorm2d-25             [-1, 64, 4, 4]             128\n",
      "             ReLU-26             [-1, 64, 4, 4]               0\n",
      "       BasicBlock-27             [-1, 64, 4, 4]               0\n",
      "           Conv2d-28             [-1, 64, 4, 4]          36,864\n",
      "      BatchNorm2d-29             [-1, 64, 4, 4]             128\n",
      "             ReLU-30             [-1, 64, 4, 4]               0\n",
      "           Conv2d-31             [-1, 64, 4, 4]          36,864\n",
      "      BatchNorm2d-32             [-1, 64, 4, 4]             128\n",
      "             ReLU-33             [-1, 64, 4, 4]               0\n",
      "       BasicBlock-34             [-1, 64, 4, 4]               0\n",
      "           Conv2d-35            [-1, 128, 2, 2]          73,728\n",
      "      BatchNorm2d-36            [-1, 128, 2, 2]             256\n",
      "             ReLU-37            [-1, 128, 2, 2]               0\n",
      "           Conv2d-38            [-1, 128, 2, 2]         147,456\n",
      "      BatchNorm2d-39            [-1, 128, 2, 2]             256\n",
      "           Conv2d-40            [-1, 128, 2, 2]           8,192\n",
      "      BatchNorm2d-41            [-1, 128, 2, 2]             256\n",
      "             ReLU-42            [-1, 128, 2, 2]               0\n",
      "       BasicBlock-43            [-1, 128, 2, 2]               0\n",
      "           Conv2d-44            [-1, 128, 2, 2]         147,456\n",
      "      BatchNorm2d-45            [-1, 128, 2, 2]             256\n",
      "             ReLU-46            [-1, 128, 2, 2]               0\n",
      "           Conv2d-47            [-1, 128, 2, 2]         147,456\n",
      "      BatchNorm2d-48            [-1, 128, 2, 2]             256\n",
      "             ReLU-49            [-1, 128, 2, 2]               0\n",
      "       BasicBlock-50            [-1, 128, 2, 2]               0\n",
      "           Conv2d-51            [-1, 256, 1, 1]         294,912\n",
      "      BatchNorm2d-52            [-1, 256, 1, 1]             512\n",
      "             ReLU-53            [-1, 256, 1, 1]               0\n",
      "           Conv2d-54            [-1, 256, 1, 1]         589,824\n",
      "      BatchNorm2d-55            [-1, 256, 1, 1]             512\n",
      "           Conv2d-56            [-1, 256, 1, 1]          32,768\n",
      "      BatchNorm2d-57            [-1, 256, 1, 1]             512\n",
      "             ReLU-58            [-1, 256, 1, 1]               0\n",
      "       BasicBlock-59            [-1, 256, 1, 1]               0\n",
      "           Conv2d-60            [-1, 256, 1, 1]         589,824\n",
      "      BatchNorm2d-61            [-1, 256, 1, 1]             512\n",
      "             ReLU-62            [-1, 256, 1, 1]               0\n",
      "           Conv2d-63            [-1, 256, 1, 1]         589,824\n",
      "      BatchNorm2d-64            [-1, 256, 1, 1]             512\n",
      "             ReLU-65            [-1, 256, 1, 1]               0\n",
      "       BasicBlock-66            [-1, 256, 1, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 256, 1, 1]               0\n",
      "           Linear-68                  [-1, 500]         128,500\n",
      "================================================================\n",
      "Total params: 2,927,380\n",
      "Trainable params: 2,927,380\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.65\n",
      "Params size (MB): 11.17\n",
      "Estimated Total Size (MB): 11.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = PATH.replace('.pth', '(GroupTaylorImportance_MetaPruner).pth')\n",
    "torch.save(model, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLOv8_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
