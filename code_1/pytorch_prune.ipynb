{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import models\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadro RTX 3000 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    device = \"cuda\"\n",
    "    print(torch.cuda.get_device_name())\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"Use CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13828\\161548569.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(PATH).to(device)\n"
     ]
    }
   ],
   "source": [
    "PATH = r\"my_weights\\Resnet18_e20_b5_t70_v30.pth\"\n",
    "model = torch.load(PATH).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 / bn1 / relu / maxpool / layer1 / layer2 / layer3 / layer4 / avgpool / fc / "
     ]
    }
   ],
   "source": [
    "for name, layer in model.named_children():\n",
    "    print(name, end=\" / \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Module : conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " / ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "conv1 / Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "bn1 / BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "relu / ReLU(inplace=True)\n",
      "maxpool / MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "layer1 / Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "layer1.0 / BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer1.0.conv1 / Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer1.0.bn1 / BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer1.0.relu / ReLU(inplace=True)\n",
      "layer1.0.conv2 / Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer1.0.bn2 / BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer1.1 / BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer1.1.conv1 / Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer1.1.bn1 / BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer1.1.relu / ReLU(inplace=True)\n",
      "layer1.1.conv2 / Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer1.1.bn2 / BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer2 / Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "layer2.0 / BasicBlock(\n",
      "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "layer2.0.conv1 / Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "layer2.0.bn1 / BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer2.0.relu / ReLU(inplace=True)\n",
      "layer2.0.conv2 / Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer2.0.bn2 / BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer2.0.downsample / Sequential(\n",
      "  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer2.0.downsample.0 / Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "layer2.0.downsample.1 / BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer2.1 / BasicBlock(\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer2.1.conv1 / Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer2.1.bn1 / BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer2.1.relu / ReLU(inplace=True)\n",
      "layer2.1.conv2 / Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer2.1.bn2 / BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer3 / Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "layer3.0 / BasicBlock(\n",
      "  (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "layer3.0.conv1 / Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "layer3.0.bn1 / BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer3.0.relu / ReLU(inplace=True)\n",
      "layer3.0.conv2 / Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer3.0.bn2 / BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer3.0.downsample / Sequential(\n",
      "  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer3.0.downsample.0 / Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "layer3.0.downsample.1 / BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer3.1 / BasicBlock(\n",
      "  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer3.1.conv1 / Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer3.1.bn1 / BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer3.1.relu / ReLU(inplace=True)\n",
      "layer3.1.conv2 / Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer3.1.bn2 / BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer4 / Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "layer4.0 / BasicBlock(\n",
      "  (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "layer4.0.conv1 / Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "layer4.0.bn1 / BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer4.0.relu / ReLU(inplace=True)\n",
      "layer4.0.conv2 / Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer4.0.bn2 / BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer4.0.downsample / Sequential(\n",
      "  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer4.0.downsample.0 / Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "layer4.0.downsample.1 / BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer4.1 / BasicBlock(\n",
      "  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer4.1.conv1 / Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer4.1.bn1 / BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer4.1.relu / ReLU(inplace=True)\n",
      "layer4.1.conv2 / Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer4.1.bn2 / BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "avgpool / AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "fc / Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    print(name, \"/\", module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## parameters:  [('weight', Parameter containing:\n",
      "tensor([[[[-1.0069e-02, -1.3557e-02, -9.1355e-03,  ...,  5.3608e-02,\n",
      "            1.6570e-02, -1.4646e-02],\n",
      "          [ 1.0844e-02,  3.3984e-03, -1.1661e-01,  ..., -2.7360e-01,\n",
      "           -1.3079e-01,  2.8700e-03],\n",
      "          [-1.1874e-02,  5.4071e-02,  2.9604e-01,  ...,  5.1904e-01,\n",
      "            2.5732e-01,  6.2824e-02],\n",
      "          ...,\n",
      "          [-3.4586e-02,  6.7463e-03,  7.2761e-02,  ..., -3.3935e-01,\n",
      "           -4.2843e-01, -2.6827e-01],\n",
      "          [ 2.6184e-02,  3.4247e-02,  5.9439e-02,  ...,  4.0480e-01,\n",
      "            3.8420e-01,  1.5571e-01],\n",
      "          [-1.6383e-02, -7.2828e-03, -2.6395e-02,  ..., -1.5636e-01,\n",
      "           -8.6250e-02, -1.2880e-02]],\n",
      "\n",
      "         [[-1.5416e-02, -4.1712e-02, -5.0123e-02,  ...,  2.0020e-02,\n",
      "           -1.0096e-02, -3.7144e-02],\n",
      "          [ 3.9152e-02,  1.9342e-02, -1.1925e-01,  ..., -3.2379e-01,\n",
      "           -1.7146e-01, -1.1399e-02],\n",
      "          [-1.1461e-02,  8.5079e-02,  3.9374e-01,  ...,  6.9820e-01,\n",
      "            3.6105e-01,  1.1450e-01],\n",
      "          ...,\n",
      "          [-6.5707e-02, -1.8273e-02,  1.6709e-02,  ..., -4.7452e-01,\n",
      "           -5.8506e-01, -3.8505e-01],\n",
      "          [ 2.5112e-02,  4.4485e-02,  9.1419e-02,  ...,  5.3215e-01,\n",
      "            4.6820e-01,  1.8168e-01],\n",
      "          [-1.3792e-03, -2.6365e-03, -2.5064e-02,  ..., -1.5884e-01,\n",
      "           -8.5899e-02, -1.2297e-02]],\n",
      "\n",
      "         [[-4.5874e-03, -1.8016e-02,  1.2971e-02,  ...,  8.3897e-02,\n",
      "            2.8392e-02, -2.5093e-02],\n",
      "          [ 1.3954e-02, -2.7401e-02, -1.3252e-01,  ..., -2.5659e-01,\n",
      "           -1.3290e-01, -3.1727e-02],\n",
      "          [ 7.5252e-03,  4.4054e-02,  2.1378e-01,  ...,  3.4666e-01,\n",
      "            1.0326e-01,  1.1262e-02],\n",
      "          ...,\n",
      "          [-3.0817e-02,  1.5054e-02,  9.7555e-02,  ..., -1.2371e-01,\n",
      "           -2.6537e-01, -1.6890e-01],\n",
      "          [ 1.7619e-02, -4.8609e-03, -3.8527e-02,  ...,  2.3094e-01,\n",
      "            2.3557e-01,  1.0303e-01],\n",
      "          [-2.4740e-03, -1.0711e-03, -1.1377e-02,  ..., -1.5181e-01,\n",
      "           -1.2065e-01, -4.4841e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7223e-02,  5.1969e-03,  1.0141e-02,  ..., -3.0821e-02,\n",
      "           -1.3487e-02, -3.9789e-02],\n",
      "          [ 6.9573e-02,  6.5056e-02,  8.8422e-02,  ...,  1.4938e-01,\n",
      "            1.5082e-01,  1.2647e-01],\n",
      "          [ 6.9201e-03,  9.5065e-03,  4.0650e-02,  ...,  6.1706e-02,\n",
      "            8.0961e-02,  1.1498e-01],\n",
      "          ...,\n",
      "          [-1.5517e-02, -1.2392e-01, -1.3513e-01,  ..., -1.3999e-01,\n",
      "           -1.1462e-01, -4.7142e-02],\n",
      "          [ 3.1927e-02, -1.3299e-02, -7.5861e-03,  ..., -1.5200e-02,\n",
      "           -2.1335e-02, -2.2225e-02],\n",
      "          [ 4.1965e-02,  3.1500e-02,  5.8546e-02,  ...,  3.2926e-02,\n",
      "            4.3196e-02,  1.9339e-02]],\n",
      "\n",
      "         [[ 1.1587e-02,  3.1361e-03,  3.3374e-02,  ...,  3.8404e-02,\n",
      "            3.4374e-02, -2.2954e-02],\n",
      "          [ 4.9764e-02,  5.9139e-02,  1.2173e-01,  ...,  2.7447e-01,\n",
      "            2.5855e-01,  1.9276e-01],\n",
      "          [-5.5454e-02, -3.5522e-02,  1.5792e-02,  ...,  1.2289e-01,\n",
      "            1.4918e-01,  1.6012e-01],\n",
      "          ...,\n",
      "          [-1.0908e-01, -2.6744e-01, -3.0919e-01,  ..., -2.9760e-01,\n",
      "           -2.2981e-01, -1.1521e-01],\n",
      "          [ 3.6936e-02, -4.5374e-02, -7.4846e-02,  ..., -1.0577e-01,\n",
      "           -8.3429e-02, -6.2230e-02],\n",
      "          [ 8.3279e-02,  8.2272e-02,  9.7052e-02,  ...,  4.3726e-02,\n",
      "            5.1882e-02,  3.2574e-02]],\n",
      "\n",
      "         [[-2.6925e-03, -1.5077e-02,  4.4875e-04,  ...,  3.8972e-02,\n",
      "            2.0601e-02, -5.1837e-02],\n",
      "          [ 4.1499e-02,  4.3038e-02,  8.9475e-02,  ...,  2.5479e-01,\n",
      "            2.2312e-01,  1.5279e-01],\n",
      "          [-4.1753e-02, -1.9642e-02,  1.9558e-02,  ...,  1.3896e-01,\n",
      "            1.1791e-01,  1.1678e-01],\n",
      "          ...,\n",
      "          [-7.0852e-02, -1.9613e-01, -2.3852e-01,  ..., -1.9909e-01,\n",
      "           -1.7056e-01, -8.8084e-02],\n",
      "          [ 4.8617e-02, -2.9487e-02, -7.3885e-02,  ..., -6.4826e-02,\n",
      "           -7.4255e-02, -5.5539e-02],\n",
      "          [ 1.1270e-01,  7.7326e-02,  6.4013e-02,  ...,  2.6679e-02,\n",
      "            1.8694e-02, -8.7813e-04]]],\n",
      "\n",
      "\n",
      "        [[[-7.0826e-08, -6.4306e-08, -7.3806e-08,  ..., -9.8000e-08,\n",
      "           -1.0905e-07, -8.3421e-08],\n",
      "          [-6.1125e-09,  2.0613e-09, -8.0922e-09,  ..., -4.9840e-08,\n",
      "           -4.3836e-08, -3.0538e-09],\n",
      "          [ 7.1953e-08,  7.5616e-08,  5.9282e-08,  ..., -9.7509e-09,\n",
      "           -1.0951e-09,  4.2442e-08],\n",
      "          ...,\n",
      "          [ 9.5889e-08,  1.0039e-07,  7.9817e-08,  ..., -1.7491e-08,\n",
      "           -4.7666e-08, -1.3265e-08],\n",
      "          [ 1.2904e-07,  1.4762e-07,  1.7477e-07,  ...,  1.3233e-07,\n",
      "            1.0628e-07,  9.3316e-08],\n",
      "          [ 1.2558e-07,  1.3644e-07,  1.8431e-07,  ...,  2.1399e-07,\n",
      "            1.7710e-07,  1.7166e-07]],\n",
      "\n",
      "         [[-1.2690e-07, -9.6139e-08, -1.0372e-07,  ..., -1.1808e-07,\n",
      "           -1.3309e-07, -1.0820e-07],\n",
      "          [-5.7412e-08, -2.5055e-08, -3.0115e-08,  ..., -7.2922e-08,\n",
      "           -6.7022e-08, -2.2574e-08],\n",
      "          [ 2.1813e-08,  4.8608e-08,  3.1222e-08,  ..., -1.8694e-08,\n",
      "           -7.9591e-09,  3.9750e-08],\n",
      "          ...,\n",
      "          [ 5.6013e-08,  7.5526e-08,  4.4496e-08,  ..., -4.4128e-08,\n",
      "           -5.9930e-08, -1.8247e-08],\n",
      "          [ 7.7614e-08,  9.8348e-08,  1.0455e-07,  ...,  6.3272e-08,\n",
      "            4.1781e-08,  4.5901e-08],\n",
      "          [ 5.9834e-08,  7.1006e-08,  9.0437e-08,  ...,  1.1654e-07,\n",
      "            8.7550e-08,  9.8837e-08]],\n",
      "\n",
      "         [[-4.3810e-08,  1.3270e-08,  7.8275e-09,  ..., -5.8804e-09,\n",
      "           -2.6217e-08, -1.5649e-08],\n",
      "          [ 4.1700e-08,  1.0778e-07,  1.0946e-07,  ...,  7.6403e-08,\n",
      "            7.1450e-08,  9.7615e-08],\n",
      "          [ 1.0436e-07,  1.6586e-07,  1.5933e-07,  ...,  1.3517e-07,\n",
      "            1.3487e-07,  1.6449e-07],\n",
      "          ...,\n",
      "          [ 9.8763e-08,  1.5072e-07,  1.2547e-07,  ...,  6.8316e-08,\n",
      "            6.8382e-08,  1.1367e-07],\n",
      "          [ 9.1435e-08,  1.3576e-07,  1.3793e-07,  ...,  1.1678e-07,\n",
      "            1.1723e-07,  1.4394e-07],\n",
      "          [ 6.2183e-08,  8.8184e-08,  1.0456e-07,  ...,  1.3941e-07,\n",
      "            1.3333e-07,  1.5844e-07]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.2823e-02, -3.4552e-02,  9.7949e-03,  ...,  3.7771e-02,\n",
      "           -3.0177e-02, -4.6541e-02],\n",
      "          [-3.9347e-02,  2.9093e-03,  3.9129e-02,  ...,  8.8965e-02,\n",
      "            5.1021e-02,  2.6526e-02],\n",
      "          [-2.5938e-02, -7.8879e-04,  1.3881e-02,  ...,  4.4393e-02,\n",
      "            3.0623e-02,  3.0184e-02],\n",
      "          ...,\n",
      "          [ 1.0636e-02,  4.3158e-02,  3.8984e-02,  ...,  3.7689e-02,\n",
      "            1.6473e-02, -7.4245e-03],\n",
      "          [-4.1925e-02, -2.6384e-02,  1.5814e-02,  ...,  4.8160e-02,\n",
      "           -1.4042e-02, -6.2625e-02],\n",
      "          [-5.0857e-02, -3.7950e-02, -1.4380e-02,  ...,  7.1593e-02,\n",
      "           -1.8352e-03, -5.0513e-02]],\n",
      "\n",
      "         [[-4.0614e-02,  4.1625e-03,  2.9215e-02,  ...,  3.4773e-02,\n",
      "           -2.0078e-02, -2.2478e-02],\n",
      "          [-1.1649e-02,  3.9563e-02,  5.9403e-02,  ...,  8.0023e-02,\n",
      "            6.1795e-02,  5.3218e-02],\n",
      "          [-6.9392e-03,  3.7020e-02,  3.6773e-02,  ...,  3.9529e-02,\n",
      "            5.0071e-02,  6.2504e-02],\n",
      "          ...,\n",
      "          [ 3.5463e-02,  7.5947e-02,  6.0111e-02,  ...,  4.3841e-02,\n",
      "            4.1214e-02,  3.3016e-02],\n",
      "          [-3.5496e-03,  2.5804e-02,  5.5294e-02,  ...,  6.9352e-02,\n",
      "            2.7184e-02, -7.4811e-05],\n",
      "          [-1.5323e-02,  1.8124e-02,  3.8549e-02,  ...,  1.0743e-01,\n",
      "            4.9709e-02,  1.1247e-02]],\n",
      "\n",
      "         [[-6.9712e-02, -3.0088e-02,  1.4468e-02,  ...,  3.7389e-02,\n",
      "           -2.8924e-02, -4.0467e-02],\n",
      "          [-1.3807e-02,  2.8357e-02,  6.0134e-02,  ...,  9.2839e-02,\n",
      "            5.8680e-02,  5.0839e-02],\n",
      "          [-1.7467e-02,  1.0442e-02,  2.0559e-02,  ...,  2.0359e-02,\n",
      "            3.3855e-02,  4.7483e-02],\n",
      "          ...,\n",
      "          [ 1.1756e-02,  4.2324e-02,  2.6321e-02,  ...,  4.3481e-03,\n",
      "           -3.2632e-03, -2.3172e-03],\n",
      "          [-1.5578e-02, -6.8689e-04,  3.4219e-02,  ...,  3.7983e-02,\n",
      "           -1.1987e-02, -2.8607e-02],\n",
      "          [-4.3818e-03,  1.0742e-02,  1.4395e-02,  ...,  6.5452e-02,\n",
      "            1.3065e-02, -2.8785e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.5319e-02,  8.0892e-03,  2.7240e-02,  ...,  2.1895e-02,\n",
      "            5.1159e-03,  1.0049e-02],\n",
      "          [ 9.0561e-03, -4.2027e-02, -4.2642e-02,  ...,  6.3230e-02,\n",
      "            3.5923e-02,  4.3289e-02],\n",
      "          [-4.4268e-02, -1.2672e-01, -1.4508e-01,  ...,  2.5044e-02,\n",
      "            3.0115e-02,  1.9026e-02],\n",
      "          ...,\n",
      "          [ 1.2742e-02,  4.4828e-04, -1.0426e-02,  ..., -3.1780e-03,\n",
      "            1.8258e-02,  1.7399e-02],\n",
      "          [-4.8445e-03,  1.7075e-02,  2.0814e-02,  ...,  2.3593e-03,\n",
      "            2.5877e-02,  5.2023e-03],\n",
      "          [ 2.4813e-04,  1.8988e-02,  8.6919e-03,  ...,  2.3322e-03,\n",
      "            1.9167e-02,  1.6743e-02]],\n",
      "\n",
      "         [[-2.2766e-02, -1.0666e-02,  1.1091e-03,  ..., -1.3812e-02,\n",
      "            5.0116e-04,  5.8632e-03],\n",
      "          [-1.4569e-02, -6.6072e-02, -6.8636e-02,  ...,  2.5219e-02,\n",
      "            1.7102e-02,  1.3068e-02],\n",
      "          [-5.9716e-02, -1.4320e-01, -1.5966e-01,  ...,  5.1238e-03,\n",
      "            2.5574e-02,  1.8710e-03],\n",
      "          ...,\n",
      "          [ 2.9229e-03, -7.1205e-03, -1.0340e-02,  ..., -5.7433e-03,\n",
      "            3.0169e-02,  1.9865e-02],\n",
      "          [ 4.6744e-03,  2.3122e-02,  3.3160e-02,  ...,  7.6811e-03,\n",
      "            4.7628e-02,  2.3111e-02],\n",
      "          [-6.1568e-03,  8.9024e-03,  8.7673e-03,  ..., -8.7711e-03,\n",
      "            3.2956e-02,  2.5827e-02]],\n",
      "\n",
      "         [[-1.7264e-02, -1.7267e-02, -5.6725e-03,  ..., -5.9074e-02,\n",
      "           -3.8464e-02, -3.7396e-02],\n",
      "          [ 1.1899e-03, -5.1326e-02, -5.7213e-02,  ..., -2.5019e-02,\n",
      "           -3.7138e-02, -5.3968e-02],\n",
      "          [-2.8641e-02, -9.4383e-02, -1.0708e-01,  ..., -2.0879e-02,\n",
      "           -1.7456e-02, -5.7505e-02],\n",
      "          ...,\n",
      "          [ 1.2945e-02, -5.9849e-04,  5.7883e-03,  ..., -3.5431e-02,\n",
      "            1.3921e-04, -1.8563e-02],\n",
      "          [ 6.2771e-03,  1.2011e-02,  2.7911e-02,  ..., -1.9625e-02,\n",
      "            2.4756e-02, -6.0016e-03],\n",
      "          [-1.8030e-02, -2.6386e-02, -2.0039e-02,  ..., -4.9837e-02,\n",
      "           -9.1664e-03, -2.2030e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1068e-02,  1.4055e-02,  2.8830e-02,  ...,  3.2855e-02,\n",
      "            2.6969e-02, -7.7204e-03],\n",
      "          [-1.2342e-02,  8.7225e-02,  1.3016e-01,  ...,  2.0861e-02,\n",
      "            7.6362e-03, -2.5570e-02],\n",
      "          [ 1.1017e-01,  1.8398e-01,  5.2038e-02,  ..., -1.6938e-01,\n",
      "           -6.7062e-02, -5.6573e-02],\n",
      "          ...,\n",
      "          [-5.1217e-02, -2.5587e-01, -2.5911e-01,  ...,  2.7308e-01,\n",
      "            1.4366e-01,  5.2544e-02],\n",
      "          [-2.3400e-02, -2.9367e-02,  1.0725e-01,  ...,  2.1685e-01,\n",
      "            8.3097e-04, -3.9275e-02],\n",
      "          [-2.9185e-02,  9.9076e-03,  8.9409e-02,  ..., -3.1896e-02,\n",
      "           -1.4092e-01, -9.1459e-02]],\n",
      "\n",
      "         [[ 1.7000e-03,  4.4960e-02,  2.9818e-02,  ...,  7.6315e-03,\n",
      "            1.6779e-02,  1.3148e-02],\n",
      "          [ 6.6106e-02,  1.5750e-01,  1.5529e-01,  ..., -2.0110e-02,\n",
      "           -1.1350e-02, -2.3536e-03],\n",
      "          [ 1.6566e-01,  2.1518e-01, -1.8353e-02,  ..., -2.6463e-01,\n",
      "           -9.9733e-02, -5.5734e-02],\n",
      "          ...,\n",
      "          [-1.2762e-01, -4.0005e-01, -3.7299e-01,  ...,  4.1899e-01,\n",
      "            2.6762e-01,  1.3738e-01],\n",
      "          [-5.8116e-02, -5.7584e-02,  1.4892e-01,  ...,  3.7146e-01,\n",
      "            1.0095e-01,  2.0612e-03],\n",
      "          [ 7.0597e-03,  5.9318e-02,  1.6242e-01,  ...,  6.4977e-02,\n",
      "           -8.9670e-02, -9.2287e-02]],\n",
      "\n",
      "         [[ 2.2314e-03,  2.8257e-02, -9.3361e-03,  ...,  2.4505e-02,\n",
      "            2.0752e-02,  3.0097e-02],\n",
      "          [ 9.5950e-03,  5.3141e-02,  6.7573e-02,  ...,  2.5054e-02,\n",
      "            4.8119e-03,  1.1907e-02],\n",
      "          [ 5.7937e-02,  1.2788e-01,  4.8359e-02,  ..., -1.3596e-01,\n",
      "           -6.7408e-02, -5.0253e-02],\n",
      "          ...,\n",
      "          [-2.7494e-02, -1.5809e-01, -1.4742e-01,  ...,  2.4163e-01,\n",
      "            1.2647e-01,  7.6242e-02],\n",
      "          [-1.2181e-02, -2.6025e-03,  8.6862e-02,  ...,  1.7262e-01,\n",
      "            3.2357e-02, -4.9532e-03],\n",
      "          [-7.0683e-03, -7.4651e-03,  3.7921e-02,  ..., -5.6797e-03,\n",
      "           -5.9185e-02, -5.8923e-02]]]], device='cuda:0', requires_grad=True))]\n",
      "## buffers:  []\n"
     ]
    }
   ],
   "source": [
    "module = model.conv1\n",
    "print(\"## parameters: \", list(module.named_parameters()))\n",
    "print(\"## buffers: \", list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning a Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Pruning module(conv1), Random Unstructured Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.random_unstructured(module, name=\"weight\", amount=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_orig', Parameter containing:\n",
      "tensor([[[[-1.0069e-02, -1.3557e-02, -9.1355e-03,  ...,  5.3608e-02,\n",
      "            1.6570e-02, -1.4646e-02],\n",
      "          [ 1.0844e-02,  3.3984e-03, -1.1661e-01,  ..., -2.7360e-01,\n",
      "           -1.3079e-01,  2.8700e-03],\n",
      "          [-1.1874e-02,  5.4071e-02,  2.9604e-01,  ...,  5.1904e-01,\n",
      "            2.5732e-01,  6.2824e-02],\n",
      "          ...,\n",
      "          [-3.4586e-02,  6.7463e-03,  7.2761e-02,  ..., -3.3935e-01,\n",
      "           -4.2843e-01, -2.6827e-01],\n",
      "          [ 2.6184e-02,  3.4247e-02,  5.9439e-02,  ...,  4.0480e-01,\n",
      "            3.8420e-01,  1.5571e-01],\n",
      "          [-1.6383e-02, -7.2828e-03, -2.6395e-02,  ..., -1.5636e-01,\n",
      "           -8.6250e-02, -1.2880e-02]],\n",
      "\n",
      "         [[-1.5416e-02, -4.1712e-02, -5.0123e-02,  ...,  2.0020e-02,\n",
      "           -1.0096e-02, -3.7144e-02],\n",
      "          [ 3.9152e-02,  1.9342e-02, -1.1925e-01,  ..., -3.2379e-01,\n",
      "           -1.7146e-01, -1.1399e-02],\n",
      "          [-1.1461e-02,  8.5079e-02,  3.9374e-01,  ...,  6.9820e-01,\n",
      "            3.6105e-01,  1.1450e-01],\n",
      "          ...,\n",
      "          [-6.5707e-02, -1.8273e-02,  1.6709e-02,  ..., -4.7452e-01,\n",
      "           -5.8506e-01, -3.8505e-01],\n",
      "          [ 2.5112e-02,  4.4485e-02,  9.1419e-02,  ...,  5.3215e-01,\n",
      "            4.6820e-01,  1.8168e-01],\n",
      "          [-1.3792e-03, -2.6365e-03, -2.5064e-02,  ..., -1.5884e-01,\n",
      "           -8.5899e-02, -1.2297e-02]],\n",
      "\n",
      "         [[-4.5874e-03, -1.8016e-02,  1.2971e-02,  ...,  8.3897e-02,\n",
      "            2.8392e-02, -2.5093e-02],\n",
      "          [ 1.3954e-02, -2.7401e-02, -1.3252e-01,  ..., -2.5659e-01,\n",
      "           -1.3290e-01, -3.1727e-02],\n",
      "          [ 7.5252e-03,  4.4054e-02,  2.1378e-01,  ...,  3.4666e-01,\n",
      "            1.0326e-01,  1.1262e-02],\n",
      "          ...,\n",
      "          [-3.0817e-02,  1.5054e-02,  9.7555e-02,  ..., -1.2371e-01,\n",
      "           -2.6537e-01, -1.6890e-01],\n",
      "          [ 1.7619e-02, -4.8609e-03, -3.8527e-02,  ...,  2.3094e-01,\n",
      "            2.3557e-01,  1.0303e-01],\n",
      "          [-2.4740e-03, -1.0711e-03, -1.1377e-02,  ..., -1.5181e-01,\n",
      "           -1.2065e-01, -4.4841e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7223e-02,  5.1969e-03,  1.0141e-02,  ..., -3.0821e-02,\n",
      "           -1.3487e-02, -3.9789e-02],\n",
      "          [ 6.9573e-02,  6.5056e-02,  8.8422e-02,  ...,  1.4938e-01,\n",
      "            1.5082e-01,  1.2647e-01],\n",
      "          [ 6.9201e-03,  9.5065e-03,  4.0650e-02,  ...,  6.1706e-02,\n",
      "            8.0961e-02,  1.1498e-01],\n",
      "          ...,\n",
      "          [-1.5517e-02, -1.2392e-01, -1.3513e-01,  ..., -1.3999e-01,\n",
      "           -1.1462e-01, -4.7142e-02],\n",
      "          [ 3.1927e-02, -1.3299e-02, -7.5861e-03,  ..., -1.5200e-02,\n",
      "           -2.1335e-02, -2.2225e-02],\n",
      "          [ 4.1965e-02,  3.1500e-02,  5.8546e-02,  ...,  3.2926e-02,\n",
      "            4.3196e-02,  1.9339e-02]],\n",
      "\n",
      "         [[ 1.1587e-02,  3.1361e-03,  3.3374e-02,  ...,  3.8404e-02,\n",
      "            3.4374e-02, -2.2954e-02],\n",
      "          [ 4.9764e-02,  5.9139e-02,  1.2173e-01,  ...,  2.7447e-01,\n",
      "            2.5855e-01,  1.9276e-01],\n",
      "          [-5.5454e-02, -3.5522e-02,  1.5792e-02,  ...,  1.2289e-01,\n",
      "            1.4918e-01,  1.6012e-01],\n",
      "          ...,\n",
      "          [-1.0908e-01, -2.6744e-01, -3.0919e-01,  ..., -2.9760e-01,\n",
      "           -2.2981e-01, -1.1521e-01],\n",
      "          [ 3.6936e-02, -4.5374e-02, -7.4846e-02,  ..., -1.0577e-01,\n",
      "           -8.3429e-02, -6.2230e-02],\n",
      "          [ 8.3279e-02,  8.2272e-02,  9.7052e-02,  ...,  4.3726e-02,\n",
      "            5.1882e-02,  3.2574e-02]],\n",
      "\n",
      "         [[-2.6925e-03, -1.5077e-02,  4.4875e-04,  ...,  3.8972e-02,\n",
      "            2.0601e-02, -5.1837e-02],\n",
      "          [ 4.1499e-02,  4.3038e-02,  8.9475e-02,  ...,  2.5479e-01,\n",
      "            2.2312e-01,  1.5279e-01],\n",
      "          [-4.1753e-02, -1.9642e-02,  1.9558e-02,  ...,  1.3896e-01,\n",
      "            1.1791e-01,  1.1678e-01],\n",
      "          ...,\n",
      "          [-7.0852e-02, -1.9613e-01, -2.3852e-01,  ..., -1.9909e-01,\n",
      "           -1.7056e-01, -8.8084e-02],\n",
      "          [ 4.8617e-02, -2.9487e-02, -7.3885e-02,  ..., -6.4826e-02,\n",
      "           -7.4255e-02, -5.5539e-02],\n",
      "          [ 1.1270e-01,  7.7326e-02,  6.4013e-02,  ...,  2.6679e-02,\n",
      "            1.8694e-02, -8.7813e-04]]],\n",
      "\n",
      "\n",
      "        [[[-7.0826e-08, -6.4306e-08, -7.3806e-08,  ..., -9.8000e-08,\n",
      "           -1.0905e-07, -8.3421e-08],\n",
      "          [-6.1125e-09,  2.0613e-09, -8.0922e-09,  ..., -4.9840e-08,\n",
      "           -4.3836e-08, -3.0538e-09],\n",
      "          [ 7.1953e-08,  7.5616e-08,  5.9282e-08,  ..., -9.7509e-09,\n",
      "           -1.0951e-09,  4.2442e-08],\n",
      "          ...,\n",
      "          [ 9.5889e-08,  1.0039e-07,  7.9817e-08,  ..., -1.7491e-08,\n",
      "           -4.7666e-08, -1.3265e-08],\n",
      "          [ 1.2904e-07,  1.4762e-07,  1.7477e-07,  ...,  1.3233e-07,\n",
      "            1.0628e-07,  9.3316e-08],\n",
      "          [ 1.2558e-07,  1.3644e-07,  1.8431e-07,  ...,  2.1399e-07,\n",
      "            1.7710e-07,  1.7166e-07]],\n",
      "\n",
      "         [[-1.2690e-07, -9.6139e-08, -1.0372e-07,  ..., -1.1808e-07,\n",
      "           -1.3309e-07, -1.0820e-07],\n",
      "          [-5.7412e-08, -2.5055e-08, -3.0115e-08,  ..., -7.2922e-08,\n",
      "           -6.7022e-08, -2.2574e-08],\n",
      "          [ 2.1813e-08,  4.8608e-08,  3.1222e-08,  ..., -1.8694e-08,\n",
      "           -7.9591e-09,  3.9750e-08],\n",
      "          ...,\n",
      "          [ 5.6013e-08,  7.5526e-08,  4.4496e-08,  ..., -4.4128e-08,\n",
      "           -5.9930e-08, -1.8247e-08],\n",
      "          [ 7.7614e-08,  9.8348e-08,  1.0455e-07,  ...,  6.3272e-08,\n",
      "            4.1781e-08,  4.5901e-08],\n",
      "          [ 5.9834e-08,  7.1006e-08,  9.0437e-08,  ...,  1.1654e-07,\n",
      "            8.7550e-08,  9.8837e-08]],\n",
      "\n",
      "         [[-4.3810e-08,  1.3270e-08,  7.8275e-09,  ..., -5.8804e-09,\n",
      "           -2.6217e-08, -1.5649e-08],\n",
      "          [ 4.1700e-08,  1.0778e-07,  1.0946e-07,  ...,  7.6403e-08,\n",
      "            7.1450e-08,  9.7615e-08],\n",
      "          [ 1.0436e-07,  1.6586e-07,  1.5933e-07,  ...,  1.3517e-07,\n",
      "            1.3487e-07,  1.6449e-07],\n",
      "          ...,\n",
      "          [ 9.8763e-08,  1.5072e-07,  1.2547e-07,  ...,  6.8316e-08,\n",
      "            6.8382e-08,  1.1367e-07],\n",
      "          [ 9.1435e-08,  1.3576e-07,  1.3793e-07,  ...,  1.1678e-07,\n",
      "            1.1723e-07,  1.4394e-07],\n",
      "          [ 6.2183e-08,  8.8184e-08,  1.0456e-07,  ...,  1.3941e-07,\n",
      "            1.3333e-07,  1.5844e-07]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.2823e-02, -3.4552e-02,  9.7949e-03,  ...,  3.7771e-02,\n",
      "           -3.0177e-02, -4.6541e-02],\n",
      "          [-3.9347e-02,  2.9093e-03,  3.9129e-02,  ...,  8.8965e-02,\n",
      "            5.1021e-02,  2.6526e-02],\n",
      "          [-2.5938e-02, -7.8879e-04,  1.3881e-02,  ...,  4.4393e-02,\n",
      "            3.0623e-02,  3.0184e-02],\n",
      "          ...,\n",
      "          [ 1.0636e-02,  4.3158e-02,  3.8984e-02,  ...,  3.7689e-02,\n",
      "            1.6473e-02, -7.4245e-03],\n",
      "          [-4.1925e-02, -2.6384e-02,  1.5814e-02,  ...,  4.8160e-02,\n",
      "           -1.4042e-02, -6.2625e-02],\n",
      "          [-5.0857e-02, -3.7950e-02, -1.4380e-02,  ...,  7.1593e-02,\n",
      "           -1.8352e-03, -5.0513e-02]],\n",
      "\n",
      "         [[-4.0614e-02,  4.1625e-03,  2.9215e-02,  ...,  3.4773e-02,\n",
      "           -2.0078e-02, -2.2478e-02],\n",
      "          [-1.1649e-02,  3.9563e-02,  5.9403e-02,  ...,  8.0023e-02,\n",
      "            6.1795e-02,  5.3218e-02],\n",
      "          [-6.9392e-03,  3.7020e-02,  3.6773e-02,  ...,  3.9529e-02,\n",
      "            5.0071e-02,  6.2504e-02],\n",
      "          ...,\n",
      "          [ 3.5463e-02,  7.5947e-02,  6.0111e-02,  ...,  4.3841e-02,\n",
      "            4.1214e-02,  3.3016e-02],\n",
      "          [-3.5496e-03,  2.5804e-02,  5.5294e-02,  ...,  6.9352e-02,\n",
      "            2.7184e-02, -7.4811e-05],\n",
      "          [-1.5323e-02,  1.8124e-02,  3.8549e-02,  ...,  1.0743e-01,\n",
      "            4.9709e-02,  1.1247e-02]],\n",
      "\n",
      "         [[-6.9712e-02, -3.0088e-02,  1.4468e-02,  ...,  3.7389e-02,\n",
      "           -2.8924e-02, -4.0467e-02],\n",
      "          [-1.3807e-02,  2.8357e-02,  6.0134e-02,  ...,  9.2839e-02,\n",
      "            5.8680e-02,  5.0839e-02],\n",
      "          [-1.7467e-02,  1.0442e-02,  2.0559e-02,  ...,  2.0359e-02,\n",
      "            3.3855e-02,  4.7483e-02],\n",
      "          ...,\n",
      "          [ 1.1756e-02,  4.2324e-02,  2.6321e-02,  ...,  4.3481e-03,\n",
      "           -3.2632e-03, -2.3172e-03],\n",
      "          [-1.5578e-02, -6.8689e-04,  3.4219e-02,  ...,  3.7983e-02,\n",
      "           -1.1987e-02, -2.8607e-02],\n",
      "          [-4.3818e-03,  1.0742e-02,  1.4395e-02,  ...,  6.5452e-02,\n",
      "            1.3065e-02, -2.8785e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.5319e-02,  8.0892e-03,  2.7240e-02,  ...,  2.1895e-02,\n",
      "            5.1159e-03,  1.0049e-02],\n",
      "          [ 9.0561e-03, -4.2027e-02, -4.2642e-02,  ...,  6.3230e-02,\n",
      "            3.5923e-02,  4.3289e-02],\n",
      "          [-4.4268e-02, -1.2672e-01, -1.4508e-01,  ...,  2.5044e-02,\n",
      "            3.0115e-02,  1.9026e-02],\n",
      "          ...,\n",
      "          [ 1.2742e-02,  4.4828e-04, -1.0426e-02,  ..., -3.1780e-03,\n",
      "            1.8258e-02,  1.7399e-02],\n",
      "          [-4.8445e-03,  1.7075e-02,  2.0814e-02,  ...,  2.3593e-03,\n",
      "            2.5877e-02,  5.2023e-03],\n",
      "          [ 2.4813e-04,  1.8988e-02,  8.6919e-03,  ...,  2.3322e-03,\n",
      "            1.9167e-02,  1.6743e-02]],\n",
      "\n",
      "         [[-2.2766e-02, -1.0666e-02,  1.1091e-03,  ..., -1.3812e-02,\n",
      "            5.0116e-04,  5.8632e-03],\n",
      "          [-1.4569e-02, -6.6072e-02, -6.8636e-02,  ...,  2.5219e-02,\n",
      "            1.7102e-02,  1.3068e-02],\n",
      "          [-5.9716e-02, -1.4320e-01, -1.5966e-01,  ...,  5.1238e-03,\n",
      "            2.5574e-02,  1.8710e-03],\n",
      "          ...,\n",
      "          [ 2.9229e-03, -7.1205e-03, -1.0340e-02,  ..., -5.7433e-03,\n",
      "            3.0169e-02,  1.9865e-02],\n",
      "          [ 4.6744e-03,  2.3122e-02,  3.3160e-02,  ...,  7.6811e-03,\n",
      "            4.7628e-02,  2.3111e-02],\n",
      "          [-6.1568e-03,  8.9024e-03,  8.7673e-03,  ..., -8.7711e-03,\n",
      "            3.2956e-02,  2.5827e-02]],\n",
      "\n",
      "         [[-1.7264e-02, -1.7267e-02, -5.6725e-03,  ..., -5.9074e-02,\n",
      "           -3.8464e-02, -3.7396e-02],\n",
      "          [ 1.1899e-03, -5.1326e-02, -5.7213e-02,  ..., -2.5019e-02,\n",
      "           -3.7138e-02, -5.3968e-02],\n",
      "          [-2.8641e-02, -9.4383e-02, -1.0708e-01,  ..., -2.0879e-02,\n",
      "           -1.7456e-02, -5.7505e-02],\n",
      "          ...,\n",
      "          [ 1.2945e-02, -5.9849e-04,  5.7883e-03,  ..., -3.5431e-02,\n",
      "            1.3921e-04, -1.8563e-02],\n",
      "          [ 6.2771e-03,  1.2011e-02,  2.7911e-02,  ..., -1.9625e-02,\n",
      "            2.4756e-02, -6.0016e-03],\n",
      "          [-1.8030e-02, -2.6386e-02, -2.0039e-02,  ..., -4.9837e-02,\n",
      "           -9.1664e-03, -2.2030e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1068e-02,  1.4055e-02,  2.8830e-02,  ...,  3.2855e-02,\n",
      "            2.6969e-02, -7.7204e-03],\n",
      "          [-1.2342e-02,  8.7225e-02,  1.3016e-01,  ...,  2.0861e-02,\n",
      "            7.6362e-03, -2.5570e-02],\n",
      "          [ 1.1017e-01,  1.8398e-01,  5.2038e-02,  ..., -1.6938e-01,\n",
      "           -6.7062e-02, -5.6573e-02],\n",
      "          ...,\n",
      "          [-5.1217e-02, -2.5587e-01, -2.5911e-01,  ...,  2.7308e-01,\n",
      "            1.4366e-01,  5.2544e-02],\n",
      "          [-2.3400e-02, -2.9367e-02,  1.0725e-01,  ...,  2.1685e-01,\n",
      "            8.3097e-04, -3.9275e-02],\n",
      "          [-2.9185e-02,  9.9076e-03,  8.9409e-02,  ..., -3.1896e-02,\n",
      "           -1.4092e-01, -9.1459e-02]],\n",
      "\n",
      "         [[ 1.7000e-03,  4.4960e-02,  2.9818e-02,  ...,  7.6315e-03,\n",
      "            1.6779e-02,  1.3148e-02],\n",
      "          [ 6.6106e-02,  1.5750e-01,  1.5529e-01,  ..., -2.0110e-02,\n",
      "           -1.1350e-02, -2.3536e-03],\n",
      "          [ 1.6566e-01,  2.1518e-01, -1.8353e-02,  ..., -2.6463e-01,\n",
      "           -9.9733e-02, -5.5734e-02],\n",
      "          ...,\n",
      "          [-1.2762e-01, -4.0005e-01, -3.7299e-01,  ...,  4.1899e-01,\n",
      "            2.6762e-01,  1.3738e-01],\n",
      "          [-5.8116e-02, -5.7584e-02,  1.4892e-01,  ...,  3.7146e-01,\n",
      "            1.0095e-01,  2.0612e-03],\n",
      "          [ 7.0597e-03,  5.9318e-02,  1.6242e-01,  ...,  6.4977e-02,\n",
      "           -8.9670e-02, -9.2287e-02]],\n",
      "\n",
      "         [[ 2.2314e-03,  2.8257e-02, -9.3361e-03,  ...,  2.4505e-02,\n",
      "            2.0752e-02,  3.0097e-02],\n",
      "          [ 9.5950e-03,  5.3141e-02,  6.7573e-02,  ...,  2.5054e-02,\n",
      "            4.8119e-03,  1.1907e-02],\n",
      "          [ 5.7937e-02,  1.2788e-01,  4.8359e-02,  ..., -1.3596e-01,\n",
      "           -6.7408e-02, -5.0253e-02],\n",
      "          ...,\n",
      "          [-2.7494e-02, -1.5809e-01, -1.4742e-01,  ...,  2.4163e-01,\n",
      "            1.2647e-01,  7.6242e-02],\n",
      "          [-1.2181e-02, -2.6025e-03,  8.6862e-02,  ...,  1.7262e-01,\n",
      "            3.2357e-02, -4.9532e-03],\n",
      "          [-7.0683e-03, -7.4651e-03,  3.7921e-02,  ..., -5.6797e-03,\n",
      "           -5.9185e-02, -5.8923e-02]]]], device='cuda:0', requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[[[1., 0., 1.,  ..., 0., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [0., 1., 0.,  ..., 0., 0., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 0., 0.],\n",
      "          [0., 1., 1.,  ..., 1., 0., 1.],\n",
      "          [0., 0., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 0., 0.,  ..., 0., 0., 1.],\n",
      "          [1., 0., 1.,  ..., 0., 1., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 0.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 0., 0.],\n",
      "          [0., 0., 1.,  ..., 1., 0., 0.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 0., 1., 1.],\n",
      "          [1., 1., 0.,  ..., 0., 0., 1.],\n",
      "          [0., 1., 1.,  ..., 1., 0., 0.],\n",
      "          ...,\n",
      "          [1., 0., 1.,  ..., 1., 1., 0.],\n",
      "          [1., 1., 0.,  ..., 0., 1., 1.],\n",
      "          [1., 1., 0.,  ..., 1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0.,  ..., 1., 1., 0.],\n",
      "          [1., 0., 1.,  ..., 0., 0., 1.],\n",
      "          [0., 0., 1.,  ..., 1., 0., 0.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 1., 1.,  ..., 1., 0., 1.],\n",
      "          [0., 0., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[0., 1., 1.,  ..., 1., 0., 1.],\n",
      "          [0., 1., 0.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 0., 0., 1.],\n",
      "          ...,\n",
      "          [1., 1., 0.,  ..., 1., 1., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 0., 1.],\n",
      "          [0., 1., 0.,  ..., 0., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 0.,  ..., 0., 1., 1.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 0.],\n",
      "          ...,\n",
      "          [1., 0., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 0., 1.,  ..., 0., 1., 1.],\n",
      "          [0., 1., 1.,  ..., 0., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0.,  ..., 0., 1., 1.],\n",
      "          [1., 1., 0.,  ..., 0., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 0., 0.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [0., 0., 1.,  ..., 1., 1., 0.],\n",
      "          [0., 1., 1.,  ..., 1., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 0., 1., 1.],\n",
      "          [0., 0., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 0.,  ..., 1., 1., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 0., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 0., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 0., 1.],\n",
      "          [1., 1., 0.,  ..., 0., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 0.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1., 0., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 0., 1., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 0., 1., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 1., 0., 1.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 0., 0.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [0., 1., 1.,  ..., 1., 0., 0.],\n",
      "          [0., 0., 1.,  ..., 0., 0., 1.]],\n",
      "\n",
      "         [[1., 1., 1.,  ..., 0., 0., 1.],\n",
      "          [1., 1., 0.,  ..., 0., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 0., 1., 0.],\n",
      "          ...,\n",
      "          [1., 1., 0.,  ..., 0., 0., 1.],\n",
      "          [0., 0., 1.,  ..., 1., 1., 0.],\n",
      "          [1., 1., 1.,  ..., 0., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 0.,  ..., 0., 0., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 0., 0.,  ..., 1., 0., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[0., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 0., 1.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 0.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [1., 0., 0.,  ..., 1., 0., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 0.]],\n",
      "\n",
      "         [[1., 0., 0.,  ..., 0., 1., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 0.],\n",
      "          [1., 0., 1.,  ..., 0., 1., 0.],\n",
      "          ...,\n",
      "          [0., 1., 1.,  ..., 0., 1., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 0., 0.],\n",
      "          [1., 0., 1.,  ..., 1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [0., 0., 1.,  ..., 1., 1., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 0.,  ..., 1., 1., 1.],\n",
      "          [1., 0., 1.,  ..., 1., 0., 0.],\n",
      "          [1., 1., 0.,  ..., 1., 0., 1.]],\n",
      "\n",
      "         [[0., 0., 1.,  ..., 0., 1., 1.],\n",
      "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 0., 1.,  ..., 0., 1., 0.],\n",
      "          [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "         [[0., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 0., 1., 1.],\n",
      "          [1., 0., 1.,  ..., 1., 0., 0.],\n",
      "          ...,\n",
      "          [1., 1., 0.,  ..., 1., 1., 1.],\n",
      "          [0., 1., 1.,  ..., 0., 1., 1.],\n",
      "          [0., 1., 1.,  ..., 1., 1., 1.]]]], device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.0069e-02, -0.0000e+00, -9.1355e-03,  ...,  0.0000e+00,\n",
      "            1.6570e-02, -1.4646e-02],\n",
      "          [ 1.0844e-02,  3.3984e-03, -1.1661e-01,  ..., -2.7360e-01,\n",
      "           -1.3079e-01,  0.0000e+00],\n",
      "          [-0.0000e+00,  5.4071e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  6.2824e-02],\n",
      "          ...,\n",
      "          [-3.4586e-02,  6.7463e-03,  7.2761e-02,  ..., -3.3935e-01,\n",
      "           -0.0000e+00, -0.0000e+00],\n",
      "          [ 0.0000e+00,  3.4247e-02,  5.9439e-02,  ...,  4.0480e-01,\n",
      "            0.0000e+00,  1.5571e-01],\n",
      "          [-0.0000e+00, -0.0000e+00, -2.6395e-02,  ..., -1.5636e-01,\n",
      "           -8.6250e-02, -1.2880e-02]],\n",
      "\n",
      "         [[-1.5416e-02, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           -0.0000e+00, -3.7144e-02],\n",
      "          [ 3.9152e-02,  0.0000e+00, -1.1925e-01,  ..., -0.0000e+00,\n",
      "           -1.7146e-01, -0.0000e+00],\n",
      "          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            3.6105e-01,  1.1450e-01],\n",
      "          ...,\n",
      "          [-6.5707e-02, -1.8273e-02,  0.0000e+00,  ..., -4.7452e-01,\n",
      "           -5.8506e-01, -3.8505e-01],\n",
      "          [ 2.5112e-02,  4.4485e-02,  9.1419e-02,  ...,  5.3215e-01,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-0.0000e+00, -0.0000e+00, -2.5064e-02,  ..., -1.5884e-01,\n",
      "           -0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "         [[-4.5874e-03, -1.8016e-02,  1.2971e-02,  ...,  0.0000e+00,\n",
      "            2.8392e-02, -2.5093e-02],\n",
      "          [ 1.3954e-02, -2.7401e-02, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           -0.0000e+00, -3.1727e-02],\n",
      "          [ 0.0000e+00,  4.4054e-02,  2.1378e-01,  ...,  3.4666e-01,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-3.0817e-02,  0.0000e+00,  9.7555e-02,  ..., -1.2371e-01,\n",
      "           -2.6537e-01, -0.0000e+00],\n",
      "          [ 1.7619e-02, -4.8609e-03, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            2.3557e-01,  1.0303e-01],\n",
      "          [-2.4740e-03, -1.0711e-03, -0.0000e+00,  ..., -1.5181e-01,\n",
      "           -0.0000e+00, -4.4841e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7223e-02,  5.1969e-03,  0.0000e+00,  ..., -3.0821e-02,\n",
      "           -1.3487e-02, -0.0000e+00],\n",
      "          [ 6.9573e-02,  0.0000e+00,  8.8422e-02,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  1.2647e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  4.0650e-02,  ...,  6.1706e-02,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.5517e-02, -1.2392e-01, -1.3513e-01,  ..., -1.3999e-01,\n",
      "           -1.1462e-01, -4.7142e-02],\n",
      "          [ 0.0000e+00, -1.3299e-02, -7.5861e-03,  ..., -1.5200e-02,\n",
      "           -0.0000e+00, -2.2225e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  5.8546e-02,  ...,  3.2926e-02,\n",
      "            4.3196e-02,  1.9339e-02]],\n",
      "\n",
      "         [[ 0.0000e+00,  3.1361e-03,  3.3374e-02,  ...,  3.8404e-02,\n",
      "            0.0000e+00, -2.2954e-02],\n",
      "          [ 0.0000e+00,  5.9139e-02,  0.0000e+00,  ...,  2.7447e-01,\n",
      "            2.5855e-01,  1.9276e-01],\n",
      "          [-5.5454e-02, -3.5522e-02,  1.5792e-02,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  1.6012e-01],\n",
      "          ...,\n",
      "          [-1.0908e-01, -2.6744e-01, -0.0000e+00,  ..., -2.9760e-01,\n",
      "           -2.2981e-01, -0.0000e+00],\n",
      "          [ 3.6936e-02, -4.5374e-02, -7.4846e-02,  ..., -1.0577e-01,\n",
      "           -0.0000e+00, -6.2230e-02],\n",
      "          [ 0.0000e+00,  8.2272e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            5.1882e-02,  3.2574e-02]],\n",
      "\n",
      "         [[-2.6925e-03, -1.5077e-02,  4.4875e-04,  ...,  3.8972e-02,\n",
      "            2.0601e-02, -5.1837e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            2.2312e-01,  1.5279e-01],\n",
      "          [-0.0000e+00, -1.9642e-02,  1.9558e-02,  ...,  1.3896e-01,\n",
      "            1.1791e-01,  0.0000e+00],\n",
      "          ...,\n",
      "          [-7.0852e-02, -0.0000e+00, -2.3852e-01,  ..., -1.9909e-01,\n",
      "           -1.7056e-01, -8.8084e-02],\n",
      "          [ 4.8617e-02, -0.0000e+00, -7.3885e-02,  ..., -0.0000e+00,\n",
      "           -7.4255e-02, -5.5539e-02],\n",
      "          [ 0.0000e+00,  7.7326e-02,  6.4013e-02,  ...,  0.0000e+00,\n",
      "            1.8694e-02, -8.7813e-04]]],\n",
      "\n",
      "\n",
      "        [[[-7.0826e-08, -6.4306e-08, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           -1.0905e-07, -8.3421e-08],\n",
      "          [-6.1125e-09,  2.0613e-09, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           -4.3836e-08, -3.0538e-09],\n",
      "          [ 7.1953e-08,  7.5616e-08,  5.9282e-08,  ..., -9.7509e-09,\n",
      "           -0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 9.5889e-08,  1.0039e-07,  7.9817e-08,  ..., -1.7491e-08,\n",
      "           -4.7666e-08, -0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  1.7477e-07,  ...,  1.3233e-07,\n",
      "            1.0628e-07,  0.0000e+00],\n",
      "          [ 0.0000e+00,  1.3644e-07,  1.8431e-07,  ...,  2.1399e-07,\n",
      "            0.0000e+00,  1.7166e-07]],\n",
      "\n",
      "         [[-1.2690e-07, -0.0000e+00, -1.0372e-07,  ..., -1.1808e-07,\n",
      "           -1.3309e-07, -1.0820e-07],\n",
      "          [-5.7412e-08, -2.5055e-08, -3.0115e-08,  ..., -0.0000e+00,\n",
      "           -6.7022e-08, -2.2574e-08],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.1222e-08,  ..., -1.8694e-08,\n",
      "           -7.9591e-09,  3.9750e-08],\n",
      "          ...,\n",
      "          [ 5.6013e-08,  7.5526e-08,  0.0000e+00,  ..., -4.4128e-08,\n",
      "           -5.9930e-08, -0.0000e+00],\n",
      "          [ 7.7614e-08,  9.8348e-08,  1.0455e-07,  ...,  6.3272e-08,\n",
      "            0.0000e+00,  4.5901e-08],\n",
      "          [ 5.9834e-08,  7.1006e-08,  9.0437e-08,  ...,  1.1654e-07,\n",
      "            8.7550e-08,  9.8837e-08]],\n",
      "\n",
      "         [[-4.3810e-08,  1.3270e-08,  7.8275e-09,  ..., -0.0000e+00,\n",
      "           -2.6217e-08, -1.5649e-08],\n",
      "          [ 4.1700e-08,  1.0778e-07,  1.0946e-07,  ...,  7.6403e-08,\n",
      "            0.0000e+00,  9.7615e-08],\n",
      "          [ 1.0436e-07,  1.6586e-07,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            1.3487e-07,  1.6449e-07],\n",
      "          ...,\n",
      "          [ 9.8763e-08,  1.5072e-07,  0.0000e+00,  ...,  6.8316e-08,\n",
      "            6.8382e-08,  1.1367e-07],\n",
      "          [ 9.1435e-08,  1.3576e-07,  1.3793e-07,  ...,  1.1678e-07,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 6.2183e-08,  8.8184e-08,  1.0456e-07,  ...,  1.3941e-07,\n",
      "            1.3333e-07,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.2823e-02, -0.0000e+00,  9.7949e-03,  ...,  3.7771e-02,\n",
      "           -3.0177e-02, -4.6541e-02],\n",
      "          [-3.9347e-02,  2.9093e-03,  3.9129e-02,  ...,  0.0000e+00,\n",
      "            5.1021e-02,  0.0000e+00],\n",
      "          [-2.5938e-02, -7.8879e-04,  1.3881e-02,  ...,  4.4393e-02,\n",
      "            3.0623e-02,  3.0184e-02],\n",
      "          ...,\n",
      "          [ 1.0636e-02,  4.3158e-02,  3.8984e-02,  ...,  0.0000e+00,\n",
      "            1.6473e-02, -0.0000e+00],\n",
      "          [-4.1925e-02, -2.6384e-02,  1.5814e-02,  ...,  4.8160e-02,\n",
      "           -1.4042e-02, -6.2625e-02],\n",
      "          [-5.0857e-02, -3.7950e-02, -1.4380e-02,  ...,  7.1593e-02,\n",
      "           -1.8352e-03, -5.0513e-02]],\n",
      "\n",
      "         [[-4.0614e-02,  4.1625e-03,  2.9215e-02,  ...,  3.4773e-02,\n",
      "           -0.0000e+00, -2.2478e-02],\n",
      "          [-0.0000e+00,  3.9563e-02,  5.9403e-02,  ...,  8.0023e-02,\n",
      "            6.1795e-02,  5.3218e-02],\n",
      "          [-6.9392e-03,  0.0000e+00,  0.0000e+00,  ...,  3.9529e-02,\n",
      "            5.0071e-02,  6.2504e-02],\n",
      "          ...,\n",
      "          [ 3.5463e-02,  7.5947e-02,  6.0111e-02,  ...,  4.3841e-02,\n",
      "            4.1214e-02,  0.0000e+00],\n",
      "          [-0.0000e+00,  2.5804e-02,  5.5294e-02,  ...,  6.9352e-02,\n",
      "            0.0000e+00, -0.0000e+00],\n",
      "          [-0.0000e+00,  0.0000e+00,  3.8549e-02,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  1.1247e-02]],\n",
      "\n",
      "         [[-6.9712e-02, -3.0088e-02,  1.4468e-02,  ...,  0.0000e+00,\n",
      "           -0.0000e+00, -4.0467e-02],\n",
      "          [-1.3807e-02,  2.8357e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            5.8680e-02,  5.0839e-02],\n",
      "          [-1.7467e-02,  1.0442e-02,  2.0559e-02,  ...,  0.0000e+00,\n",
      "            3.3855e-02,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.1756e-02,  4.2324e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           -0.0000e+00, -2.3172e-03],\n",
      "          [-0.0000e+00, -0.0000e+00,  3.4219e-02,  ...,  3.7983e-02,\n",
      "           -1.1987e-02, -0.0000e+00],\n",
      "          [-4.3818e-03,  1.0742e-02,  1.4395e-02,  ...,  0.0000e+00,\n",
      "            1.3065e-02, -2.8785e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.5319e-02,  8.0892e-03,  2.7240e-02,  ...,  2.1895e-02,\n",
      "            5.1159e-03,  1.0049e-02],\n",
      "          [ 9.0561e-03, -4.2027e-02, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  4.3289e-02],\n",
      "          [-4.4268e-02, -1.2672e-01, -1.4508e-01,  ...,  2.5044e-02,\n",
      "            3.0115e-02,  1.9026e-02],\n",
      "          ...,\n",
      "          [ 1.2742e-02,  0.0000e+00, -0.0000e+00,  ..., -3.1780e-03,\n",
      "            0.0000e+00,  1.7399e-02],\n",
      "          [-4.8445e-03,  1.7075e-02,  2.0814e-02,  ...,  2.3593e-03,\n",
      "            2.5877e-02,  5.2023e-03],\n",
      "          [ 0.0000e+00,  0.0000e+00,  8.6919e-03,  ...,  2.3322e-03,\n",
      "            1.9167e-02,  1.6743e-02]],\n",
      "\n",
      "         [[-0.0000e+00, -1.0666e-02,  1.1091e-03,  ..., -1.3812e-02,\n",
      "            5.0116e-04,  0.0000e+00],\n",
      "          [-1.4569e-02, -6.6072e-02, -6.8636e-02,  ...,  2.5219e-02,\n",
      "            0.0000e+00,  1.3068e-02],\n",
      "          [-0.0000e+00, -1.4320e-01, -1.5966e-01,  ...,  5.1238e-03,\n",
      "            2.5574e-02,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.9229e-03, -7.1205e-03, -1.0340e-02,  ..., -5.7433e-03,\n",
      "            3.0169e-02,  0.0000e+00],\n",
      "          [ 4.6744e-03,  0.0000e+00,  0.0000e+00,  ...,  7.6811e-03,\n",
      "            0.0000e+00,  2.3111e-02],\n",
      "          [-6.1568e-03,  8.9024e-03,  8.7673e-03,  ..., -8.7711e-03,\n",
      "            3.2956e-02,  0.0000e+00]],\n",
      "\n",
      "         [[-1.7264e-02, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           -3.8464e-02, -0.0000e+00],\n",
      "          [ 1.1899e-03, -5.1326e-02, -5.7213e-02,  ..., -2.5019e-02,\n",
      "           -3.7138e-02, -0.0000e+00],\n",
      "          [-2.8641e-02, -0.0000e+00, -1.0708e-01,  ..., -0.0000e+00,\n",
      "           -1.7456e-02, -0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -5.9849e-04,  5.7883e-03,  ..., -0.0000e+00,\n",
      "            1.3921e-04, -0.0000e+00],\n",
      "          [ 6.2771e-03,  1.2011e-02,  2.7911e-02,  ..., -1.9625e-02,\n",
      "            0.0000e+00, -0.0000e+00],\n",
      "          [-1.8030e-02, -0.0000e+00, -2.0039e-02,  ..., -4.9837e-02,\n",
      "           -9.1664e-03, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-3.1068e-02,  1.4055e-02,  2.8830e-02,  ...,  3.2855e-02,\n",
      "            2.6969e-02, -7.7204e-03],\n",
      "          [-0.0000e+00,  0.0000e+00,  1.3016e-01,  ...,  2.0861e-02,\n",
      "            7.6362e-03, -0.0000e+00],\n",
      "          [ 1.1017e-01,  1.8398e-01,  5.2038e-02,  ..., -1.6938e-01,\n",
      "           -6.7062e-02, -5.6573e-02],\n",
      "          ...,\n",
      "          [-5.1217e-02, -2.5587e-01, -0.0000e+00,  ...,  2.7308e-01,\n",
      "            1.4366e-01,  5.2544e-02],\n",
      "          [-2.3400e-02, -0.0000e+00,  1.0725e-01,  ...,  2.1685e-01,\n",
      "            0.0000e+00, -0.0000e+00],\n",
      "          [-2.9185e-02,  9.9076e-03,  0.0000e+00,  ..., -3.1896e-02,\n",
      "           -0.0000e+00, -9.1459e-02]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  2.9818e-02,  ...,  0.0000e+00,\n",
      "            1.6779e-02,  1.3148e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  1.5529e-01,  ..., -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00],\n",
      "          [ 1.6566e-01,  2.1518e-01, -1.8353e-02,  ..., -2.6463e-01,\n",
      "           -9.9733e-02, -5.5734e-02],\n",
      "          ...,\n",
      "          [-1.2762e-01, -0.0000e+00, -3.7299e-01,  ...,  0.0000e+00,\n",
      "            2.6762e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -5.7584e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            1.0095e-01,  0.0000e+00],\n",
      "          [ 7.0597e-03,  5.9318e-02,  1.6242e-01,  ...,  6.4977e-02,\n",
      "           -8.9670e-02, -9.2287e-02]],\n",
      "\n",
      "         [[ 0.0000e+00,  2.8257e-02, -9.3361e-03,  ...,  2.4505e-02,\n",
      "            2.0752e-02,  3.0097e-02],\n",
      "          [ 9.5950e-03,  5.3141e-02,  6.7573e-02,  ...,  0.0000e+00,\n",
      "            4.8119e-03,  1.1907e-02],\n",
      "          [ 5.7937e-02,  0.0000e+00,  4.8359e-02,  ..., -1.3596e-01,\n",
      "           -0.0000e+00, -0.0000e+00],\n",
      "          ...,\n",
      "          [-2.7494e-02, -1.5809e-01, -0.0000e+00,  ...,  2.4163e-01,\n",
      "            1.2647e-01,  7.6242e-02],\n",
      "          [-0.0000e+00, -2.6025e-03,  8.6862e-02,  ...,  0.0000e+00,\n",
      "            3.2357e-02, -4.9532e-03],\n",
      "          [-0.0000e+00, -7.4651e-03,  3.7921e-02,  ..., -5.6797e-03,\n",
      "           -5.9185e-02, -5.8923e-02]]]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.remove(module, 'weight') # 將 weight_orig、weight_mask 刪除，並新增 weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[[[-1.0069e-02, -0.0000e+00, -9.1355e-03,  ...,  0.0000e+00,\n",
      "            1.6570e-02, -1.4646e-02],\n",
      "          [ 1.0844e-02,  3.3984e-03, -1.1661e-01,  ..., -2.7360e-01,\n",
      "           -1.3079e-01,  0.0000e+00],\n",
      "          [-0.0000e+00,  5.4071e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  6.2824e-02],\n",
      "          ...,\n",
      "          [-3.4586e-02,  6.7463e-03,  7.2761e-02,  ..., -3.3935e-01,\n",
      "           -0.0000e+00, -0.0000e+00],\n",
      "          [ 0.0000e+00,  3.4247e-02,  5.9439e-02,  ...,  4.0480e-01,\n",
      "            0.0000e+00,  1.5571e-01],\n",
      "          [-0.0000e+00, -0.0000e+00, -2.6395e-02,  ..., -1.5636e-01,\n",
      "           -8.6250e-02, -1.2880e-02]],\n",
      "\n",
      "         [[-1.5416e-02, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           -0.0000e+00, -3.7144e-02],\n",
      "          [ 3.9152e-02,  0.0000e+00, -1.1925e-01,  ..., -0.0000e+00,\n",
      "           -1.7146e-01, -0.0000e+00],\n",
      "          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            3.6105e-01,  1.1450e-01],\n",
      "          ...,\n",
      "          [-6.5707e-02, -1.8273e-02,  0.0000e+00,  ..., -4.7452e-01,\n",
      "           -5.8506e-01, -3.8505e-01],\n",
      "          [ 2.5112e-02,  4.4485e-02,  9.1419e-02,  ...,  5.3215e-01,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-0.0000e+00, -0.0000e+00, -2.5064e-02,  ..., -1.5884e-01,\n",
      "           -0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "         [[-4.5874e-03, -1.8016e-02,  1.2971e-02,  ...,  0.0000e+00,\n",
      "            2.8392e-02, -2.5093e-02],\n",
      "          [ 1.3954e-02, -2.7401e-02, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           -0.0000e+00, -3.1727e-02],\n",
      "          [ 0.0000e+00,  4.4054e-02,  2.1378e-01,  ...,  3.4666e-01,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-3.0817e-02,  0.0000e+00,  9.7555e-02,  ..., -1.2371e-01,\n",
      "           -2.6537e-01, -0.0000e+00],\n",
      "          [ 1.7619e-02, -4.8609e-03, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            2.3557e-01,  1.0303e-01],\n",
      "          [-2.4740e-03, -1.0711e-03, -0.0000e+00,  ..., -1.5181e-01,\n",
      "           -0.0000e+00, -4.4841e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7223e-02,  5.1969e-03,  0.0000e+00,  ..., -3.0821e-02,\n",
      "           -1.3487e-02, -0.0000e+00],\n",
      "          [ 6.9573e-02,  0.0000e+00,  8.8422e-02,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  1.2647e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  4.0650e-02,  ...,  6.1706e-02,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.5517e-02, -1.2392e-01, -1.3513e-01,  ..., -1.3999e-01,\n",
      "           -1.1462e-01, -4.7142e-02],\n",
      "          [ 0.0000e+00, -1.3299e-02, -7.5861e-03,  ..., -1.5200e-02,\n",
      "           -0.0000e+00, -2.2225e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  5.8546e-02,  ...,  3.2926e-02,\n",
      "            4.3196e-02,  1.9339e-02]],\n",
      "\n",
      "         [[ 0.0000e+00,  3.1361e-03,  3.3374e-02,  ...,  3.8404e-02,\n",
      "            0.0000e+00, -2.2954e-02],\n",
      "          [ 0.0000e+00,  5.9139e-02,  0.0000e+00,  ...,  2.7447e-01,\n",
      "            2.5855e-01,  1.9276e-01],\n",
      "          [-5.5454e-02, -3.5522e-02,  1.5792e-02,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  1.6012e-01],\n",
      "          ...,\n",
      "          [-1.0908e-01, -2.6744e-01, -0.0000e+00,  ..., -2.9760e-01,\n",
      "           -2.2981e-01, -0.0000e+00],\n",
      "          [ 3.6936e-02, -4.5374e-02, -7.4846e-02,  ..., -1.0577e-01,\n",
      "           -0.0000e+00, -6.2230e-02],\n",
      "          [ 0.0000e+00,  8.2272e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            5.1882e-02,  3.2574e-02]],\n",
      "\n",
      "         [[-2.6925e-03, -1.5077e-02,  4.4875e-04,  ...,  3.8972e-02,\n",
      "            2.0601e-02, -5.1837e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            2.2312e-01,  1.5279e-01],\n",
      "          [-0.0000e+00, -1.9642e-02,  1.9558e-02,  ...,  1.3896e-01,\n",
      "            1.1791e-01,  0.0000e+00],\n",
      "          ...,\n",
      "          [-7.0852e-02, -0.0000e+00, -2.3852e-01,  ..., -1.9909e-01,\n",
      "           -1.7056e-01, -8.8084e-02],\n",
      "          [ 4.8617e-02, -0.0000e+00, -7.3885e-02,  ..., -0.0000e+00,\n",
      "           -7.4255e-02, -5.5539e-02],\n",
      "          [ 0.0000e+00,  7.7326e-02,  6.4013e-02,  ...,  0.0000e+00,\n",
      "            1.8694e-02, -8.7813e-04]]],\n",
      "\n",
      "\n",
      "        [[[-7.0826e-08, -6.4306e-08, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           -1.0905e-07, -8.3421e-08],\n",
      "          [-6.1125e-09,  2.0613e-09, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           -4.3836e-08, -3.0538e-09],\n",
      "          [ 7.1953e-08,  7.5616e-08,  5.9282e-08,  ..., -9.7509e-09,\n",
      "           -0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 9.5889e-08,  1.0039e-07,  7.9817e-08,  ..., -1.7491e-08,\n",
      "           -4.7666e-08, -0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  1.7477e-07,  ...,  1.3233e-07,\n",
      "            1.0628e-07,  0.0000e+00],\n",
      "          [ 0.0000e+00,  1.3644e-07,  1.8431e-07,  ...,  2.1399e-07,\n",
      "            0.0000e+00,  1.7166e-07]],\n",
      "\n",
      "         [[-1.2690e-07, -0.0000e+00, -1.0372e-07,  ..., -1.1808e-07,\n",
      "           -1.3309e-07, -1.0820e-07],\n",
      "          [-5.7412e-08, -2.5055e-08, -3.0115e-08,  ..., -0.0000e+00,\n",
      "           -6.7022e-08, -2.2574e-08],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.1222e-08,  ..., -1.8694e-08,\n",
      "           -7.9591e-09,  3.9750e-08],\n",
      "          ...,\n",
      "          [ 5.6013e-08,  7.5526e-08,  0.0000e+00,  ..., -4.4128e-08,\n",
      "           -5.9930e-08, -0.0000e+00],\n",
      "          [ 7.7614e-08,  9.8348e-08,  1.0455e-07,  ...,  6.3272e-08,\n",
      "            0.0000e+00,  4.5901e-08],\n",
      "          [ 5.9834e-08,  7.1006e-08,  9.0437e-08,  ...,  1.1654e-07,\n",
      "            8.7550e-08,  9.8837e-08]],\n",
      "\n",
      "         [[-4.3810e-08,  1.3270e-08,  7.8275e-09,  ..., -0.0000e+00,\n",
      "           -2.6217e-08, -1.5649e-08],\n",
      "          [ 4.1700e-08,  1.0778e-07,  1.0946e-07,  ...,  7.6403e-08,\n",
      "            0.0000e+00,  9.7615e-08],\n",
      "          [ 1.0436e-07,  1.6586e-07,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            1.3487e-07,  1.6449e-07],\n",
      "          ...,\n",
      "          [ 9.8763e-08,  1.5072e-07,  0.0000e+00,  ...,  6.8316e-08,\n",
      "            6.8382e-08,  1.1367e-07],\n",
      "          [ 9.1435e-08,  1.3576e-07,  1.3793e-07,  ...,  1.1678e-07,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [ 6.2183e-08,  8.8184e-08,  1.0456e-07,  ...,  1.3941e-07,\n",
      "            1.3333e-07,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.2823e-02, -0.0000e+00,  9.7949e-03,  ...,  3.7771e-02,\n",
      "           -3.0177e-02, -4.6541e-02],\n",
      "          [-3.9347e-02,  2.9093e-03,  3.9129e-02,  ...,  0.0000e+00,\n",
      "            5.1021e-02,  0.0000e+00],\n",
      "          [-2.5938e-02, -7.8879e-04,  1.3881e-02,  ...,  4.4393e-02,\n",
      "            3.0623e-02,  3.0184e-02],\n",
      "          ...,\n",
      "          [ 1.0636e-02,  4.3158e-02,  3.8984e-02,  ...,  0.0000e+00,\n",
      "            1.6473e-02, -0.0000e+00],\n",
      "          [-4.1925e-02, -2.6384e-02,  1.5814e-02,  ...,  4.8160e-02,\n",
      "           -1.4042e-02, -6.2625e-02],\n",
      "          [-5.0857e-02, -3.7950e-02, -1.4380e-02,  ...,  7.1593e-02,\n",
      "           -1.8352e-03, -5.0513e-02]],\n",
      "\n",
      "         [[-4.0614e-02,  4.1625e-03,  2.9215e-02,  ...,  3.4773e-02,\n",
      "           -0.0000e+00, -2.2478e-02],\n",
      "          [-0.0000e+00,  3.9563e-02,  5.9403e-02,  ...,  8.0023e-02,\n",
      "            6.1795e-02,  5.3218e-02],\n",
      "          [-6.9392e-03,  0.0000e+00,  0.0000e+00,  ...,  3.9529e-02,\n",
      "            5.0071e-02,  6.2504e-02],\n",
      "          ...,\n",
      "          [ 3.5463e-02,  7.5947e-02,  6.0111e-02,  ...,  4.3841e-02,\n",
      "            4.1214e-02,  0.0000e+00],\n",
      "          [-0.0000e+00,  2.5804e-02,  5.5294e-02,  ...,  6.9352e-02,\n",
      "            0.0000e+00, -0.0000e+00],\n",
      "          [-0.0000e+00,  0.0000e+00,  3.8549e-02,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  1.1247e-02]],\n",
      "\n",
      "         [[-6.9712e-02, -3.0088e-02,  1.4468e-02,  ...,  0.0000e+00,\n",
      "           -0.0000e+00, -4.0467e-02],\n",
      "          [-1.3807e-02,  2.8357e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            5.8680e-02,  5.0839e-02],\n",
      "          [-1.7467e-02,  1.0442e-02,  2.0559e-02,  ...,  0.0000e+00,\n",
      "            3.3855e-02,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.1756e-02,  4.2324e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           -0.0000e+00, -2.3172e-03],\n",
      "          [-0.0000e+00, -0.0000e+00,  3.4219e-02,  ...,  3.7983e-02,\n",
      "           -1.1987e-02, -0.0000e+00],\n",
      "          [-4.3818e-03,  1.0742e-02,  1.4395e-02,  ...,  0.0000e+00,\n",
      "            1.3065e-02, -2.8785e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.5319e-02,  8.0892e-03,  2.7240e-02,  ...,  2.1895e-02,\n",
      "            5.1159e-03,  1.0049e-02],\n",
      "          [ 9.0561e-03, -4.2027e-02, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  4.3289e-02],\n",
      "          [-4.4268e-02, -1.2672e-01, -1.4508e-01,  ...,  2.5044e-02,\n",
      "            3.0115e-02,  1.9026e-02],\n",
      "          ...,\n",
      "          [ 1.2742e-02,  0.0000e+00, -0.0000e+00,  ..., -3.1780e-03,\n",
      "            0.0000e+00,  1.7399e-02],\n",
      "          [-4.8445e-03,  1.7075e-02,  2.0814e-02,  ...,  2.3593e-03,\n",
      "            2.5877e-02,  5.2023e-03],\n",
      "          [ 0.0000e+00,  0.0000e+00,  8.6919e-03,  ...,  2.3322e-03,\n",
      "            1.9167e-02,  1.6743e-02]],\n",
      "\n",
      "         [[-0.0000e+00, -1.0666e-02,  1.1091e-03,  ..., -1.3812e-02,\n",
      "            5.0116e-04,  0.0000e+00],\n",
      "          [-1.4569e-02, -6.6072e-02, -6.8636e-02,  ...,  2.5219e-02,\n",
      "            0.0000e+00,  1.3068e-02],\n",
      "          [-0.0000e+00, -1.4320e-01, -1.5966e-01,  ...,  5.1238e-03,\n",
      "            2.5574e-02,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.9229e-03, -7.1205e-03, -1.0340e-02,  ..., -5.7433e-03,\n",
      "            3.0169e-02,  0.0000e+00],\n",
      "          [ 4.6744e-03,  0.0000e+00,  0.0000e+00,  ...,  7.6811e-03,\n",
      "            0.0000e+00,  2.3111e-02],\n",
      "          [-6.1568e-03,  8.9024e-03,  8.7673e-03,  ..., -8.7711e-03,\n",
      "            3.2956e-02,  0.0000e+00]],\n",
      "\n",
      "         [[-1.7264e-02, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           -3.8464e-02, -0.0000e+00],\n",
      "          [ 1.1899e-03, -5.1326e-02, -5.7213e-02,  ..., -2.5019e-02,\n",
      "           -3.7138e-02, -0.0000e+00],\n",
      "          [-2.8641e-02, -0.0000e+00, -1.0708e-01,  ..., -0.0000e+00,\n",
      "           -1.7456e-02, -0.0000e+00],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -5.9849e-04,  5.7883e-03,  ..., -0.0000e+00,\n",
      "            1.3921e-04, -0.0000e+00],\n",
      "          [ 6.2771e-03,  1.2011e-02,  2.7911e-02,  ..., -1.9625e-02,\n",
      "            0.0000e+00, -0.0000e+00],\n",
      "          [-1.8030e-02, -0.0000e+00, -2.0039e-02,  ..., -4.9837e-02,\n",
      "           -9.1664e-03, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-3.1068e-02,  1.4055e-02,  2.8830e-02,  ...,  3.2855e-02,\n",
      "            2.6969e-02, -7.7204e-03],\n",
      "          [-0.0000e+00,  0.0000e+00,  1.3016e-01,  ...,  2.0861e-02,\n",
      "            7.6362e-03, -0.0000e+00],\n",
      "          [ 1.1017e-01,  1.8398e-01,  5.2038e-02,  ..., -1.6938e-01,\n",
      "           -6.7062e-02, -5.6573e-02],\n",
      "          ...,\n",
      "          [-5.1217e-02, -2.5587e-01, -0.0000e+00,  ...,  2.7308e-01,\n",
      "            1.4366e-01,  5.2544e-02],\n",
      "          [-2.3400e-02, -0.0000e+00,  1.0725e-01,  ...,  2.1685e-01,\n",
      "            0.0000e+00, -0.0000e+00],\n",
      "          [-2.9185e-02,  9.9076e-03,  0.0000e+00,  ..., -3.1896e-02,\n",
      "           -0.0000e+00, -9.1459e-02]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  2.9818e-02,  ...,  0.0000e+00,\n",
      "            1.6779e-02,  1.3148e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  1.5529e-01,  ..., -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00],\n",
      "          [ 1.6566e-01,  2.1518e-01, -1.8353e-02,  ..., -2.6463e-01,\n",
      "           -9.9733e-02, -5.5734e-02],\n",
      "          ...,\n",
      "          [-1.2762e-01, -0.0000e+00, -3.7299e-01,  ...,  0.0000e+00,\n",
      "            2.6762e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -5.7584e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            1.0095e-01,  0.0000e+00],\n",
      "          [ 7.0597e-03,  5.9318e-02,  1.6242e-01,  ...,  6.4977e-02,\n",
      "           -8.9670e-02, -9.2287e-02]],\n",
      "\n",
      "         [[ 0.0000e+00,  2.8257e-02, -9.3361e-03,  ...,  2.4505e-02,\n",
      "            2.0752e-02,  3.0097e-02],\n",
      "          [ 9.5950e-03,  5.3141e-02,  6.7573e-02,  ...,  0.0000e+00,\n",
      "            4.8119e-03,  1.1907e-02],\n",
      "          [ 5.7937e-02,  0.0000e+00,  4.8359e-02,  ..., -1.3596e-01,\n",
      "           -0.0000e+00, -0.0000e+00],\n",
      "          ...,\n",
      "          [-2.7494e-02, -1.5809e-01, -0.0000e+00,  ...,  2.4163e-01,\n",
      "            1.2647e-01,  7.6242e-02],\n",
      "          [-0.0000e+00, -2.6025e-03,  8.6862e-02,  ...,  0.0000e+00,\n",
      "            3.2357e-02, -4.9532e-03],\n",
      "          [-0.0000e+00, -7.4651e-03,  3.7921e-02,  ..., -5.6797e-03,\n",
      "           -5.9185e-02, -5.8923e-02]]]], device='cuda:0', requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = PATH.replace('.pth', '(conv1 sp=0.3).pth')\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Pruning\n",
    "Resnet18: 對 conv1 / layer1 / layer2 / layer3 / layer4 / fc 做剪枝 \n",
    "1. prune.RandomUnstructured\n",
    "2. prune.l1_unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13828\\1493793539.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(PATH).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 61, 16, 16]           8,967\n",
      "       BatchNorm2d-2           [-1, 61, 16, 16]             122\n",
      "              ReLU-3           [-1, 61, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 61, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]          35,136\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 61, 8, 8]          35,136\n",
      "       BatchNorm2d-9             [-1, 61, 8, 8]             122\n",
      "             ReLU-10             [-1, 61, 8, 8]               0\n",
      "       BasicBlock-11             [-1, 61, 8, 8]               0\n",
      "           Conv2d-12             [-1, 64, 8, 8]          35,136\n",
      "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
      "             ReLU-14             [-1, 64, 8, 8]               0\n",
      "           Conv2d-15             [-1, 61, 8, 8]          35,136\n",
      "      BatchNorm2d-16             [-1, 61, 8, 8]             122\n",
      "             ReLU-17             [-1, 61, 8, 8]               0\n",
      "       BasicBlock-18             [-1, 61, 8, 8]               0\n",
      "           Conv2d-19            [-1, 128, 4, 4]          70,272\n",
      "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
      "             ReLU-21            [-1, 128, 4, 4]               0\n",
      "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
      "           Conv2d-24            [-1, 128, 4, 4]           7,808\n",
      "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
      "             ReLU-26            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
      "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
      "             ReLU-30            [-1, 128, 4, 4]               0\n",
      "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
      "             ReLU-33            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
      "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
      "             ReLU-37            [-1, 256, 2, 2]               0\n",
      "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
      "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
      "             ReLU-42            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
      "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
      "             ReLU-46            [-1, 256, 2, 2]               0\n",
      "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
      "             ReLU-49            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
      "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-53            [-1, 512, 1, 1]               0\n",
      "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-58            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
      "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-62            [-1, 512, 1, 1]               0\n",
      "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-65            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,678,301\n",
      "Trainable params: 11,678,301\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.26\n",
      "Params size (MB): 44.55\n",
      "Estimated Total Size (MB): 45.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "PATH = r\"my_weights\\Resnet18_e20_b5_t70_v30.pth\"\n",
    "model = torch.load(PATH).to(device)\n",
    "summary(model, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = [\n",
    "    (model.conv1, \"weight\"), # Conv2d\n",
    "    (model.fc, \"weight\") # Linear\n",
    "] \n",
    "\n",
    "for layer in [model.layer1, model.layer2, model.layer3, model.layer4]:\n",
    "    for block in layer:\n",
    "        for name, module in block.named_modules():\n",
    "            if isinstance(module, torch.nn.Conv2d):\n",
    "                parameters_to_prune.append((module, 'weight'))\n",
    "\n",
    "# for module in parameters_to_prune:\n",
    "#     print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pruning\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    # pruning_method=prune.RandomUnstructured,\n",
    "    amount=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in conv1.weight: 19.96%\n",
      "Sparsity in layer1[0].conv1.weight: 26.13%\n",
      "Sparsity in layer1[0].conv2.weight: 15.75%\n",
      "Sparsity in layer1[1].conv1.weight: 15.26%\n",
      "Sparsity in layer1[1].conv2.weight: 15.62%\n",
      "     ......      \n",
      "Sparsity in fc.weight: 6.59%\n",
      "Global sparsity: 30.00%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.conv1.weight == 0))\n",
    "        / float(model.conv1.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in layer1[0].conv1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.layer1[0].conv1.weight == 0))\n",
    "        / float(model.layer1[0].conv1.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in layer1[0].conv2.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.layer1[0].conv2.weight == 0))\n",
    "        / float(model.layer1[0].conv2.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in layer1[1].conv1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.layer1[1].conv1.weight == 0))\n",
    "        / float(model.layer1[1].conv1.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in layer1[1].conv2.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.layer1[1].conv2.weight == 0))\n",
    "        / float(model.layer1[1].conv2.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\"     ......      \")\n",
    "print(\n",
    "    \"Sparsity in fc.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.fc.weight == 0))\n",
    "        / float(model.fc.weight.nelement())\n",
    "    )\n",
    ")\n",
    "########################################################################\n",
    "count_0 = 0\n",
    "count_total = 0\n",
    "for module, _ in parameters_to_prune:\n",
    "    count_0 += torch.sum(module.weight == 0)\n",
    "    count_total += module.weight.nelement()\n",
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(count_0) / float(count_total)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module, _ in parameters_to_prune:\n",
    "    prune.remove(module, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
      "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
      "             ReLU-14             [-1, 64, 8, 8]               0\n",
      "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
      "             ReLU-17             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
      "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
      "             ReLU-21            [-1, 128, 4, 4]               0\n",
      "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
      "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
      "             ReLU-26            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
      "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
      "             ReLU-30            [-1, 128, 4, 4]               0\n",
      "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
      "             ReLU-33            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
      "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
      "             ReLU-37            [-1, 256, 2, 2]               0\n",
      "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
      "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
      "             ReLU-42            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
      "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
      "             ReLU-46            [-1, 256, 2, 2]               0\n",
      "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
      "             ReLU-49            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
      "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-53            [-1, 512, 1, 1]               0\n",
      "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-58            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
      "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-62            [-1, 512, 1, 1]               0\n",
      "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-65            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.29\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 45.90\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 32, 32)) # Unstruced 剪枝的話，Param 不會改變\n",
    "# print(model.conv1.weight) # 確認有剪枝到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = PATH.replace('.pth', '(global L1-norm sp=0.3).pth')\n",
    "torch.save(model, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLOv8_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
