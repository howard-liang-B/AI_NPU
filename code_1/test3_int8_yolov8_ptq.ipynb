{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    }
   ],
   "source": [
    "#動態qat\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    " \n",
    " \n",
    "model_fp32 =\"/home/11126110/FPGA/CLAHE_yolov5n_experiment3/weights/yolov8_LP30_tooth.onnx\"\n",
    "model_int8 = 'test3_dynamic_quantized.onnx'\n",
    " \n",
    " \n",
    "# Quantize \n",
    "quantize_dynamic(model_fp32, model_int8, weight_type=QuantType.QUInt8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始進行靜態量化...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider pre-processing before quantization. See https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "靜態量化完成! 輸出模型保存在: static_quantized_model.onnx\n"
     ]
    }
   ],
   "source": [
    "#靜態qat\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from onnxruntime.quantization import CalibrationDataReader, quantize_static, QuantType, QuantFormat\n",
    "from glob import glob\n",
    "\n",
    "class ImageCalibrationDataReader(CalibrationDataReader):\n",
    "    def __init__(self, image_folder):\n",
    "        self.image_paths = glob(os.path.join(image_folder, \"*\"))\n",
    "        self.idx = 0\n",
    "        self.input_name = \"images\"\n",
    "    \n",
    "    def preprocess(self, frame):\n",
    "        # 圖像預處理\n",
    "        frame = cv2.imread(frame)\n",
    "        if frame is None:\n",
    "            raise ValueError(f\"無法讀取圖片: {frame}\")\n",
    "            \n",
    "        X = cv2.resize(frame, (640, 640))\n",
    "        image_data = np.array(X).astype(np.float32) / 255.0  # 正規化到 [0, 1]\n",
    "        image_data = np.transpose(image_data, (2, 0, 1))  # (H, W, C) -> (C, H, W)\n",
    "        image_data = np.expand_dims(image_data, axis=0)  # 添加批次維度\n",
    "        return image_data\n",
    "    \n",
    "    def get_next(self):\n",
    "        if self.idx >= len(self.image_paths):\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            image_path = self.image_paths[self.idx]\n",
    "            input_data = self.preprocess(image_path)\n",
    "            self.idx += 1\n",
    "            return {self.input_name: input_data}\n",
    "        except Exception as e:\n",
    "            print(f\"處理圖片時發生錯誤 {image_path}: {str(e)}\")\n",
    "            self.idx += 1\n",
    "            return self.get_next()\n",
    "\n",
    "def main():\n",
    "    # 設定路徑\n",
    "    model_path = \"/home/11126110/FPGA/CLAHE_yolov5n_experiment3/weights/yolov8_LP30_tooth.onnx\"\n",
    "    calibration_data_path = \"/home/11126110/FPGA/CLAHE-image-crop/test/images\"\n",
    "    output_model_path = \"static_quantized_model.onnx\"\n",
    "    \n",
    "    # 確認文件是否存在\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"找不到模型文件: {model_path}\")\n",
    "    if not os.path.exists(calibration_data_path):\n",
    "        raise FileNotFoundError(f\"找不到校準數據文件夾: {calibration_data_path}\")\n",
    "    \n",
    "    # 創建校準數據讀取器\n",
    "    calibration_data_reader = ImageCalibrationDataReader(calibration_data_path)\n",
    "    \n",
    "    # 設定需要排除的節點\n",
    "    #Concat、Split、Slice 操作：用於處理預測張量\n",
    "    #Add、Sub、Div、Mul 操作：用於邊界框計算和調整\n",
    "    #Sigmoid：非線性激活函數，量化可能導致精度損失\n",
    "    #Softmax：用於類別預測的概率計算，需要保持精確度\n",
    "    #Reshape、Transpose 操作：純粹的數據重組操作\n",
    "    \n",
    "    nodes_to_exclude = [\n",
    "        '/model.22/Concat_3', '/model.22/Split', '/model.22/Sigmoid',\n",
    "        '/model.22/dfl/Reshape', '/model.22/dfl/Transpose', '/model.22/dfl/Softmax', \n",
    "        '/model.22/dfl/conv/Conv', '/model.22/dfl/Reshape_1', '/model.22/Slice_1',\n",
    "        '/model.22/Slice', '/model.22/Add_1', '/model.22/Sub', '/model.22/Div_1',\n",
    "        '/model.22/Concat_4', '/model.22/Mul_2', '/model.22/Concat_5'\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        print(\"開始進行靜態量化...\")\n",
    "        # 執行靜態量化\n",
    "        quantize_static(\n",
    "            model_path,\n",
    "            output_model_path,\n",
    "            weight_type=QuantType.QInt8,\n",
    "            activation_type=QuantType.QUInt8,\n",
    "            calibration_data_reader=calibration_data_reader,\n",
    "            quant_format=QuantFormat.QDQ,\n",
    "            nodes_to_exclude=nodes_to_exclude,\n",
    "            per_channel=False,\n",
    "            reduce_range=True\n",
    "        )\n",
    "        print(f\"靜態量化完成! 輸出模型保存在: {output_model_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"量化過程中發生錯誤: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadro RTX 3000 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    device = \"cuda\"\n",
    "    print(torch.cuda.get_device_name())\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"Use CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Providers: ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Device:  GPU\n",
      "\n",
      "=== 驗證原始模型 (GPU) ===\n",
      "use:  ['CUDAExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "驗證中: 100%|██████████| 6/6 [00:01<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "原始模型結果:\n",
      "Precision: 0.9600\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.9796\n",
      "Average IOU: 0.8930\n",
      "mAP@50: 1.0000\n",
      "mAP@50-95: 0.8294\n",
      "Total GT: 24.0000\n",
      "Total Predictions: 25.0000\n",
      "Correct Detections: 24.0000\n",
      "Total Inference Time (ms): 1428.88 ms\n",
      "Average Inference Time (ms): 238.15 ms\n",
      "\n",
      "=== 驗證量化後模型 (GPU) ===\n",
      "use:  ['CUDAExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "驗證中: 100%|██████████| 6/6 [00:01<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "量化後模型結果:\n",
      "Precision: 0.9600\n",
      "Recall: 1.0000\n",
      "F1-Score: 0.9796\n",
      "Average IOU: 0.8743\n",
      "mAP@50: 1.0000\n",
      "mAP@50-95: 0.7820\n",
      "Total GT: 24.0000\n",
      "Total Predictions: 25.0000\n",
      "Correct Detections: 24.0000\n",
      "Total Inference Time (ms): 1044.89 ms\n",
      "Average Inference Time (ms): 174.15 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#gpu驗證\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils import yaml_load\n",
    "from ultralytics.utils.checks import check_yaml\n",
    "\n",
    "class YOLOValidator:\n",
    "    def __init__(self, model_path, image_size=640):\n",
    "        self.image_size = image_size\n",
    "        self.conf_threshold = 0.25\n",
    "        self.iou_threshold = 0.45\n",
    "        \n",
    "        # 配置 GPU 推理選項\n",
    "        providers = [\n",
    "            ('CUDAExecutionProvider', {\n",
    "                'device_id': torch.cuda.current_device(),\n",
    "                'arena_extend_strategy': 'kNextPowerOfTwo',\n",
    "                'gpu_mem_limit': 1 * 1024 * 1024 * 1024,   # 20GB GPU memory limit\n",
    "                'cudnn_conv_algo_search': 'EXHAUSTIVE',     \n",
    "                'do_copy_in_default_stream': True,\n",
    "            }),\n",
    "            # 'CPUExecutionProvider'\n",
    "        ]\n",
    "        \n",
    "        # 創建啟用 GPU 的 session\n",
    "        sess_options = ort.SessionOptions()\n",
    "        sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "        sess_options.intra_op_num_threads = 1  # 設置內部操作的執行線程數\n",
    "        sess_options.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL\n",
    "        \n",
    "        self.session = ort.InferenceSession(\n",
    "            model_path, \n",
    "            sess_options=sess_options,\n",
    "            providers=providers\n",
    "        )\n",
    "        print(\"use: \", self.session.get_providers())\n",
    "        \n",
    "        self.input_name = self.session.get_inputs()[0].name\n",
    "        \n",
    "        # mAP計算用的IoU閾值\n",
    "        self.iou_thresholds = np.linspace(0.5, 0.95, 10)  # [0.5, 0.55, ..., 0.95]\n",
    "\n",
    "    def preprocess_image(self, image_path):\n",
    "        img = cv2.imread(image_path)\n",
    "        original_shape = img.shape[:2]\n",
    "        \n",
    "        img = cv2.resize(img, (self.image_size, self.image_size))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        return img, original_shape\n",
    "\n",
    "    \n",
    "    def parse_label_line(self, line):\n",
    "            values = list(map(float, line.strip().split()))\n",
    "            class_id = int(values[0])\n",
    "            points = []\n",
    "            \n",
    "            for i in range(1, len(values), 2):\n",
    "                if i + 1 < len(values):\n",
    "                    x, y = values[i], values[i + 1]\n",
    "                    points.append((x, y))\n",
    "                    \n",
    "            return class_id, points\n",
    "\n",
    "    def calculate_polygon_bbox(self, points):\n",
    "        if not points:\n",
    "            return None\n",
    "            \n",
    "        x_coords = [p[0] for p in points]\n",
    "        y_coords = [p[1] for p in points]\n",
    "        \n",
    "        x_min, x_max = min(x_coords), max(x_coords)\n",
    "        y_min, y_max = min(y_coords), max(y_coords)\n",
    "        \n",
    "        x_center = (x_min + x_max) / 2\n",
    "        y_center = (y_min + y_max) / 2\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        \n",
    "        return [x_center, y_center, width, height]\n",
    "\n",
    "    def post_process(self, outputs, original_shape):\n",
    "        output = outputs[0][0]  # [5, 8400]\n",
    "        predictions = output.transpose()  # [8400, 5]\n",
    "        \n",
    "        scores = predictions[:, 4]\n",
    "        mask = scores > self.conf_threshold\n",
    "        predictions = predictions[mask]\n",
    "        \n",
    "        if len(predictions) == 0:\n",
    "            return []\n",
    "        \n",
    "        boxes = np.zeros_like(predictions[:, :4])\n",
    "        boxes[:, 0] = predictions[:, 0] - predictions[:, 2] / 2  # x1\n",
    "        boxes[:, 1] = predictions[:, 1] - predictions[:, 3] / 2  # y1\n",
    "        boxes[:, 2] = predictions[:, 0] + predictions[:, 2] / 2  # x2\n",
    "        boxes[:, 3] = predictions[:, 1] + predictions[:, 3] / 2  # y2\n",
    "        \n",
    "        scores = predictions[:, 4]\n",
    "        indices = cv2.dnn.NMSBoxes(boxes.tolist(), scores.tolist(), \n",
    "                                 self.conf_threshold, \n",
    "                                 self.iou_threshold)\n",
    "        \n",
    "        scale_x = original_shape[1] / self.image_size\n",
    "        scale_y = original_shape[0] / self.image_size\n",
    "        \n",
    "        results = []\n",
    "        if len(indices) > 0:\n",
    "            for idx in indices:\n",
    "                box = boxes[idx]\n",
    "                x1, y1, x2, y2 = box\n",
    "                \n",
    "                x1 *= scale_x\n",
    "                x2 *= scale_x\n",
    "                y1 *= scale_y\n",
    "                y2 *= scale_y\n",
    "                \n",
    "                confidence = float(predictions[idx, 4])\n",
    "                \n",
    "                width = (x2 - x1)\n",
    "                height = (y2 - y1)\n",
    "                x_center = x1 + width / 2\n",
    "                y_center = y1 + height / 2\n",
    "                \n",
    "                x_center /= original_shape[1]\n",
    "                y_center /= original_shape[0]\n",
    "                width /= original_shape[1]\n",
    "                height /= original_shape[0]\n",
    "                \n",
    "                class_id = 0\n",
    "                \n",
    "                results.append([class_id, x_center, y_center, width, height, confidence])\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def calculate_iou(self, box1, box2):\n",
    "        b1_x1 = box1[1] - box1[3] / 2\n",
    "        b1_y1 = box1[2] - box1[4] / 2\n",
    "        b1_x2 = box1[1] + box1[3] / 2\n",
    "        b1_y2 = box1[2] + box1[4] / 2\n",
    "        \n",
    "        b2_x1 = box2[1] - box2[3] / 2\n",
    "        b2_y1 = box2[2] - box2[4] / 2\n",
    "        b2_x2 = box2[1] + box2[3] / 2\n",
    "        b2_y2 = box2[2] + box2[4] / 2\n",
    "        \n",
    "        inter_x1 = max(b1_x1, b2_x1)\n",
    "        inter_y1 = max(b1_y1, b2_y1)\n",
    "        inter_x2 = min(b1_x2, b2_x2)\n",
    "        inter_y2 = min(b1_y2, b2_y2)\n",
    "        \n",
    "        inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
    "        \n",
    "        b1_area = (b1_x2 - b1_x1) * (b1_y2 - b1_y1)\n",
    "        b2_area = (b2_x2 - b2_x1) * (b2_y2 - b2_y1)\n",
    "        \n",
    "        iou = inter_area / (b1_area + b2_area - inter_area + 1e-16)\n",
    "        \n",
    "        return iou\n",
    "\n",
    "    def calculate_map(self, all_predictions, all_ground_truths, iou_threshold):\n",
    "        \"\"\"計算單一IoU閾值下的mAP\"\"\"\n",
    "        if not all_predictions or not all_ground_truths:\n",
    "            return 0.0\n",
    "        \n",
    "        # 按置信度降序排序所有預測\n",
    "        all_predictions.sort(key=lambda x: x[5], reverse=True)\n",
    "        \n",
    "        total_gts = len(all_ground_truths)\n",
    "        detected = [False] * total_gts\n",
    "        true_positives = []\n",
    "        false_positives = []\n",
    "        \n",
    "        for pred in all_predictions:\n",
    "            max_iou = 0\n",
    "            max_idx = -1\n",
    "            \n",
    "            # 找到與當前預測框IoU最大的真實框\n",
    "            for gt_idx, gt in enumerate(all_ground_truths):\n",
    "                if not detected[gt_idx]:  # 只考慮未被檢測到的真實框\n",
    "                    iou = self.calculate_iou(pred, gt)\n",
    "                    if iou > max_iou:\n",
    "                        max_iou = iou\n",
    "                        max_idx = gt_idx\n",
    "            \n",
    "            # 根據IoU閾值判定是否為真陽性\n",
    "            if max_iou >= iou_threshold and max_idx != -1:\n",
    "                detected[max_idx] = True\n",
    "                true_positives.append(1)\n",
    "                false_positives.append(0)\n",
    "            else:\n",
    "                true_positives.append(0)\n",
    "                false_positives.append(1)\n",
    "        \n",
    "        # 計算累積值\n",
    "        cumsum_tp = np.cumsum(true_positives)\n",
    "        cumsum_fp = np.cumsum(false_positives)\n",
    "        \n",
    "        # 計算查全率和查準率\n",
    "        recalls = cumsum_tp / total_gts if total_gts > 0 else np.zeros_like(cumsum_tp)\n",
    "        precisions = cumsum_tp / (cumsum_tp + cumsum_fp)\n",
    "        \n",
    "        # 計算AP\n",
    "        ap = 0\n",
    "        for t in np.arange(0, 1.1, 0.1):  # [0, 0.1, ..., 1.0]\n",
    "            if np.sum(recalls >= t) == 0:\n",
    "                p = 0\n",
    "            else:\n",
    "                p = np.max(precisions[recalls >= t])\n",
    "            ap += p / 11\n",
    "        \n",
    "        return ap\n",
    "\n",
    "    def validate(self, image_dir, label_dir):\n",
    "        total_gt = 0\n",
    "        total_pred = 0\n",
    "        total_correct = 0\n",
    "        total_iou = 0\n",
    "        total_inference_time = 0\n",
    "        \n",
    "        all_predictions = []\n",
    "        all_ground_truths = []\n",
    "        \n",
    "        image_paths = sorted(Path(image_dir).glob(\"*.*\"))\n",
    "        total_images = len(image_paths)\n",
    "        \n",
    "        for image_path in tqdm(image_paths, desc=\"驗證中\"):\n",
    "            label_path = Path(label_dir) / f\"{image_path.stem}.txt\"\n",
    "            if not label_path.exists():\n",
    "                continue\n",
    "                \n",
    "            gt_boxes = []\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    class_id, points = self.parse_label_line(line)\n",
    "                    bbox = self.calculate_polygon_bbox(points)\n",
    "                    if bbox:\n",
    "                        gt_boxes.append([class_id] + bbox)\n",
    "            \n",
    "            img, original_shape = self.preprocess_image(str(image_path))\n",
    "            \n",
    "            # 使用毫秒計算推理時間\n",
    "            start_time = time.perf_counter()\n",
    "            outputs = self.session.run(None, {self.input_name: img})\n",
    "            inference_time = (time.perf_counter() - start_time) * 1000  # 轉換為毫秒\n",
    "            total_inference_time += inference_time\n",
    "            \n",
    "            pred_boxes = self.post_process(outputs, original_shape)\n",
    "            \n",
    "            all_predictions.extend(pred_boxes)\n",
    "            all_ground_truths.extend(gt_boxes)\n",
    "            \n",
    "            total_gt += len(gt_boxes)\n",
    "            total_pred += len(pred_boxes)\n",
    "            \n",
    "            for gt_box in gt_boxes:\n",
    "                max_iou = 0\n",
    "                for pred_box in pred_boxes:\n",
    "                    if gt_box[0] == pred_box[0]:\n",
    "                        iou = self.calculate_iou(gt_box, pred_box)\n",
    "                        max_iou = max(max_iou, iou)\n",
    "                \n",
    "                if max_iou > 0.5:\n",
    "                    total_correct += 1\n",
    "                    total_iou += max_iou\n",
    "        \n",
    "        precision = total_correct / total_pred if total_pred > 0 else 0\n",
    "        recall = total_correct / total_gt if total_gt > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        avg_iou = total_iou / total_correct if total_correct > 0 else 0\n",
    "        \n",
    "        map50 = self.calculate_map(all_predictions, all_ground_truths, 0.5)\n",
    "        \n",
    "        map_list = []\n",
    "        for iou_threshold in self.iou_thresholds:\n",
    "            map_value = self.calculate_map(all_predictions, all_ground_truths, iou_threshold)\n",
    "            map_list.append(map_value)\n",
    "        map50_95 = np.mean(map_list) # change \n",
    "        \n",
    "        # 計算平均推理時間（毫秒）\n",
    "        avg_inference_time = total_inference_time / total_images\n",
    "        \n",
    "        return {\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1_score,\n",
    "            'Average IOU': avg_iou,\n",
    "            'mAP@50': map50,\n",
    "            'mAP@50-95': map50_95,\n",
    "            'Total GT': total_gt,\n",
    "            'Total Predictions': total_pred,\n",
    "            'Correct Detections': total_correct,\n",
    "            'Total Inference Time (ms)': total_inference_time,\n",
    "            'Average Inference Time (ms)': avg_inference_time\n",
    "        }\n",
    "    #目前最好/home/11126110/FPGA/aggoptimized_yolov8_quantized_model_int8.onnx\n",
    "def main():\n",
    "    model_path = r'runs\\iter5_LPr30\\step_4_finetune\\weights\\yolov8_LP30_tooth.onnx'\n",
    "    quantized_model_path = r'C:\\Users\\user\\Desktop\\AI_npu\\code\\my_weights\\static_quantized_model.onnx'\n",
    "    image_dir = r\"C:\\Users\\user\\Desktop\\AI_npu\\code\\tooth_dataset\\valid3\\images\"\n",
    "    label_dir = r\"C:\\Users\\user\\Desktop\\AI_npu\\code\\tooth_dataset\\valid3\\labels\"\n",
    "    \n",
    "    print(\"\\nAvailable Providers:\", ort.get_available_providers())\n",
    "    print(\"Device: \", ort.get_device())\n",
    "    \n",
    "    print(\"\\n=== 驗證原始模型 (GPU) ===\")\n",
    "    validator = YOLOValidator(model_path)\n",
    "    results = validator.validate(image_dir, label_dir)\n",
    "    # pruning_cfg = yaml_load(check_yaml(r\"C:\\Users\\user\\Desktop\\AI_npu\\code\\tooth_dataset\\default.yaml\"))\n",
    "    # onnx_model = YOLO(model_path)\n",
    "    # onnx_model.val(**pruning_cfg)\n",
    "    \n",
    "    print(\"\\n原始模型結果:\")\n",
    "    for metric, value in results.items():\n",
    "        if 'Time' in metric:\n",
    "            print(f\"{metric}: {value:.2f} ms\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== 驗證量化後模型 (GPU) ===\")\n",
    "    validator_quantized = YOLOValidator(quantized_model_path)\n",
    "    results_quantized = validator_quantized.validate(image_dir, label_dir)\n",
    "    # onnx_model = YOLO(quantized_model_path)\n",
    "    # onnx_model.val(**pruning_cfg)\n",
    "    \n",
    "    print(\"\\n量化後模型結果:\")\n",
    "    for metric, value in results_quantized.items():\n",
    "        if 'Time' in metric:\n",
    "            print(f\"{metric}: {value:.2f} ms\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 21 23:04:40 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.97                 Driver Version: 555.97         CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Quadro RTX 3000 with Max...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   45C    P5              9W /   60W |      91MiB /   6144MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      7512      C   ...naconda3\\envs\\YOLOv8_env\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLOv8_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
