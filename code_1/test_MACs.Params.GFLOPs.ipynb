{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Model Metrics ====================\n",
      "\n",
      "Total MACs: 4.04G\n",
      "Total Parameters: 3.01M\n",
      "Total GFLOPs: 8.08\n",
      "\n",
      "==================== Layer Statistics ====================\n",
      "Layer Type      Count    MACs         Params      \n",
      "-----------------------------------------------\n",
      "Add             9        0.00K        0.00K       \n",
      "Concat          19       0.00K        0.00K       \n",
      "Constant        22       0.00K        0.00K       \n",
      "Conv            64       4.04G        3.01M       \n",
      "Div             2        0.00K        0.00K       \n",
      "Gather          1        0.00K        0.00K       \n",
      "MaxPool         3        0.00K        0.00K       \n",
      "Mul             60       0.00K        0.00K       \n",
      "Reshape         5        0.00K        0.00K       \n",
      "Resize          2        0.00K        0.00K       \n",
      "Shape           1        0.00K        0.00K       \n",
      "Sigmoid         58       0.00K        0.00K       \n",
      "Slice           2        0.00K        0.00K       \n",
      "Softmax         1        0.00K        0.00K       \n",
      "Split           9        0.00K        0.00K       \n",
      "Sub             2        0.00K        0.00K       \n",
      "Transpose       1        0.00K        0.00K       \n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "def get_shape_from_value_info(value_info) -> list:\n",
    "    \"\"\"Helper function to extract shape from ValueInfoProto\"\"\"\n",
    "    if not value_info.type.tensor_type.shape.dim:\n",
    "        return []\n",
    "    return [dim.dim_value if dim.dim_value != 0 else 1 \n",
    "            for dim in value_info.type.tensor_type.shape.dim]\n",
    "\n",
    "def get_node_input_shape(node, value_info: Dict, initializers: Dict) -> list:\n",
    "    \"\"\"Get input shapes for a node\"\"\"\n",
    "    shapes = []\n",
    "    for input_name in node.input:\n",
    "        if input_name in value_info:\n",
    "            shapes.append(get_shape_from_value_info(value_info[input_name]))\n",
    "        elif input_name in initializers:\n",
    "            shapes.append(list(initializers[input_name].dims))\n",
    "    return shapes\n",
    "\n",
    "def get_node_output_shape(node, value_info: Dict) -> list:\n",
    "    \"\"\"Get output shapes for a node\"\"\"\n",
    "    shapes = []\n",
    "    for output_name in node.output:\n",
    "        if output_name in value_info:\n",
    "            shapes.append(get_shape_from_value_info(value_info[output_name]))\n",
    "    return shapes\n",
    "\n",
    "def calculate_conv_macs_params(node, input_shape, output_shape) -> Tuple[int, int]:\n",
    "    \"\"\"Calculate MACs and parameters for Conv layers\"\"\"\n",
    "    attrs = {attr.name: attr for attr in node.attribute}\n",
    "    \n",
    "    kernel_shape = attrs['kernel_shape'].ints if 'kernel_shape' in attrs else [1, 1]\n",
    "    group = attrs['group'].i if 'group' in attrs else 1\n",
    "    \n",
    "    # Handle cases where shapes might be incomplete\n",
    "    if len(input_shape) < 4 or len(output_shape) < 4:\n",
    "        return 0, 0\n",
    "        \n",
    "    in_channels = input_shape[1]\n",
    "    out_channels = output_shape[1]\n",
    "    \n",
    "    output_height = output_shape[2]\n",
    "    output_width = output_shape[3]\n",
    "    \n",
    "    # Calculate parameters and MACs\n",
    "    params = (in_channels * kernel_shape[0] * kernel_shape[1] * out_channels // group) + out_channels\n",
    "    macs = (params - out_channels) * output_height * output_width\n",
    "    \n",
    "    return macs, params\n",
    "\n",
    "def analyze_model_metrics(model_path: str) -> Dict:\n",
    "    \"\"\"Analyze ONNX model metrics\"\"\"\n",
    "    model = onnx.load(model_path)\n",
    "    graph = model.graph\n",
    "    \n",
    "    # Build value_info dictionary\n",
    "    value_info = {}\n",
    "    initializers = {init.name: init for init in graph.initializer}\n",
    "    \n",
    "    # Add input shapes\n",
    "    for input_info in graph.input:\n",
    "        value_info[input_info.name] = input_info\n",
    "        \n",
    "    # Add output shapes\n",
    "    for output_info in graph.output:\n",
    "        value_info[output_info.name] = output_info\n",
    "        \n",
    "    # Add value_info shapes\n",
    "    for info in graph.value_info:\n",
    "        value_info[info.name] = info\n",
    "    \n",
    "    # Try to infer shapes if possible\n",
    "    try:\n",
    "        model_with_shapes = onnx.shape_inference.infer_shapes(model)\n",
    "        for info in model_with_shapes.graph.value_info:\n",
    "            value_info[info.name] = info\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Shape inference failed: {e}\")\n",
    "    \n",
    "    total_macs = 0\n",
    "    total_params = 0\n",
    "    layer_stats = defaultdict(lambda: {'count': 0, 'macs': 0, 'params': 0})\n",
    "    \n",
    "    for node in graph.node:\n",
    "        op_type = node.op_type\n",
    "        layer_stats[op_type]['count'] += 1\n",
    "        \n",
    "        input_shapes = get_node_input_shape(node, value_info, initializers)\n",
    "        output_shapes = get_node_output_shape(node, value_info)\n",
    "        \n",
    "        if not input_shapes or not output_shapes:\n",
    "            continue\n",
    "            \n",
    "        macs = params = 0\n",
    "        \n",
    "        if op_type == 'Conv':\n",
    "            macs, params = calculate_conv_macs_params(node, input_shapes[0], output_shapes[0])\n",
    "        elif op_type == 'Gemm':\n",
    "            if len(input_shapes[0]) > 0 and len(output_shapes[0]) > 0:\n",
    "                in_features = np.prod(input_shapes[0][1:])  # Handle flattened inputs\n",
    "                out_features = output_shapes[0][1]\n",
    "                params = in_features * out_features + out_features\n",
    "                macs = in_features * out_features\n",
    "        \n",
    "        layer_stats[op_type]['macs'] += macs\n",
    "        layer_stats[op_type]['params'] += params\n",
    "        total_macs += macs\n",
    "        total_params += params\n",
    "    \n",
    "    total_flops = total_macs * 2\n",
    "    gflops = total_flops / 1e9\n",
    "    \n",
    "    return {\n",
    "        'total_macs': total_macs,\n",
    "        'total_params': total_params,\n",
    "        'total_gflops': gflops,\n",
    "        'layer_stats': dict(layer_stats)\n",
    "    }\n",
    "\n",
    "def format_number(num: int) -> str:\n",
    "    \"\"\"Format number to millions or billions\"\"\"\n",
    "    if num >= 1e9:\n",
    "        return f\"{num/1e9:.2f}G\"\n",
    "    elif num >= 1e6:\n",
    "        return f\"{num/1e6:.2f}M\"\n",
    "    else:\n",
    "        return f\"{num:.2f}K\"\n",
    "\n",
    "def print_model_metrics(model_path: str):\n",
    "    \"\"\"Print model metrics\"\"\"\n",
    "    print(f\"\\n{'='*20} Model Metrics {'='*20}\")\n",
    "    \n",
    "    try:\n",
    "        metrics = analyze_model_metrics(model_path)\n",
    "        \n",
    "        print(f\"\\nTotal MACs: {format_number(metrics['total_macs'])}\")\n",
    "        print(f\"Total Parameters: {format_number(metrics['total_params'])}\")\n",
    "        print(f\"Total GFLOPs: {metrics['total_gflops']:.2f}\")\n",
    "        \n",
    "        print(f\"\\n{'='*20} Layer Statistics {'='*20}\")\n",
    "        print(f\"{'Layer Type':<15} {'Count':<8} {'MACs':<12} {'Params':<12}\")\n",
    "        print(\"-\" * 47)\n",
    "        \n",
    "        for layer_type, stats in sorted(metrics['layer_stats'].items()):\n",
    "            if stats['count'] > 0:\n",
    "                print(f\"{layer_type:<15} {stats['count']:<8} {format_number(stats['macs']):<12} {format_number(stats['params']):<12}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing model: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path =  r\"C:\\Users\\user\\Desktop\\AI_npu\\code\\runs\\pruning_onnx\\tooth.onnx\"\n",
    "    print_model_metrics(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.254659519634412"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.76679 / 3.01104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2461538461538462"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8.1 /6.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLOv8_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
